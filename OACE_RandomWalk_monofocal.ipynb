{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8sySYFxXdlI"
      },
      "source": [
        "Importando Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk_zvCtgXYfI",
        "outputId": "a51d884c-2a55-48a0-bbb8-424a48569f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchtext in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (0.18.0)\n",
            "Requirement already satisfied: torchdata in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (0.11.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchdata) (2.2.1)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests->torchtext) (2024.6.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torchtext) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyDecision in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (4.5.8)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (3.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.26.4)\n",
            "Requirement already satisfied: llmx in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (0.0.21a0)\n",
            "Requirement already satisfied: openai in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.35.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.5.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.14.0)\n",
            "Requirement already satisfied: pydantic in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (2.7.4)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (0.7.0)\n",
            "Requirement already satisfied: diskcache in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (5.6.3)\n",
            "Requirement already satisfied: cohere in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (5.5.8)\n",
            "Requirement already satisfied: google.auth in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (2.30.0)\n",
            "Requirement already satisfied: typer in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (0.12.3)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (0.27.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pyDecision) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pyDecision) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->pyDecision) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->pyDecision) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai->pyDecision) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai->pyDecision) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai->pyDecision) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->pyDecision) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->llmx->pyDecision) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->llmx->pyDecision) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->pyDecision) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai->pyDecision) (0.4.6)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (1.34.133)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (1.9.4)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (0.9.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (2.32.0.20240622)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from google.auth->llmx->pyDecision) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from google.auth->llmx->pyDecision) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from google.auth->llmx->pyDecision) (4.9)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken->llmx->pyDecision) (2024.5.15)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from typer->llmx->pyDecision) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from typer->llmx->pyDecision) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from typer->llmx->pyDecision) (13.7.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.133 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from boto3<2.0.0,>=1.34.0->cohere->llmx->pyDecision) (1.34.133)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from boto3<2.0.0,>=1.34.0->cohere->llmx->pyDecision) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from boto3<2.0.0,>=1.34.0->cohere->llmx->pyDecision) (0.10.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyasn1-modules>=0.2.1->google.auth->llmx->pyDecision) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere->llmx->pyDecision) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere->llmx->pyDecision) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer->llmx->pyDecision) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer->llmx->pyDecision) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers<1,>=0.15->cohere->llmx->pyDecision) (0.23.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere->llmx->pyDecision) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere->llmx->pyDecision) (2024.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->llmx->pyDecision) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install pyDecision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GAEO2YhZXbMr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision.models.inception import InceptionOutputs\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from pyDecision.algorithm import ahp_method\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh3htiCcXfmT"
      },
      "source": [
        "Carregando DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Js9BBmIsMJOA"
      },
      "outputs": [],
      "source": [
        "zip_dataset_warm = '/content/dataset-resized'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPbti20RYEFU",
        "outputId": "a1f9b7af-5b25-4133-e752-e2461c3dbe9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCN3ILrWYGZM"
      },
      "outputs": [],
      "source": [
        "def cifar_10(n_valid=0.2, batch_size=64, num_workers=4):\n",
        "    \"\"\"10 Classes\"\"\"\n",
        "    \n",
        "    transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Resize((224, 224)),\n",
        "                                    transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])])\n",
        "    \n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])  \n",
        "    ])\n",
        "    \n",
        "    train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "    test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "    n_train = len(train_data)\n",
        "    indices = list(range(n_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(n_valid * n_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # Define samplers for obtaining training and validation\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # Prepare data loaders (combine dataset and sampler)\n",
        "    trainLoader = torch.utils.data.DataLoader(train_data,\n",
        "                                            batch_size = batch_size,\n",
        "                                            sampler = train_sampler,\n",
        "                                            num_workers = num_workers)\n",
        "\n",
        "    validLoader = torch.utils.data.DataLoader(train_data,\n",
        "                                            batch_size = batch_size,\n",
        "                                            sampler = valid_sampler,\n",
        "                                            num_workers = num_workers)\n",
        "\n",
        "    testLoader = torch.utils.data.DataLoader(test_data,\n",
        "                                            batch_size = batch_size,\n",
        "                                            num_workers = num_workers)\n",
        "\n",
        "    classes = train_data.classes\n",
        "    return trainLoader, validLoader, testLoader, classes\n",
        "\n",
        "##### AJUSTA PARA CIFAR-10 SUBSAMPLE #####################\n",
        "\n",
        "def cifar_10_subsample(batch_size=64, num_workers=4, class_labels=['cat', 'dog']):\n",
        "    \"\"\"CIFAR-10 with only two selected classes for warm\"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Resize((224, 224)),\n",
        "                                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "    \n",
        "    # Load the entire CIFAR-10 test dataset\n",
        "    test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "    # Filter out only the specified classes\n",
        "    test_indices = [i for i, label in enumerate(test_data.targets) if test_data.classes[label] in class_labels]\n",
        "\n",
        "    # Map the selected classes to new labels (0 and 1)\n",
        "    test_data.targets = [test_data.targets[i] for i in test_indices]\n",
        "    test_data.data = test_data.data[test_indices]\n",
        "\n",
        "    label_map = {test_data.classes.index(class_labels[0]): 0,\n",
        "                 test_data.classes.index(class_labels[1]): 1}\n",
        "\n",
        "    test_data.targets = [label_map[label] for label in test_data.targets]\n",
        "\n",
        "    # Prepare data loader for test data\n",
        "    testLoader = DataLoader(test_data, \n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers)\n",
        "    \n",
        "    classes = class_labels\n",
        "    \n",
        "    return testLoader, classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcdgrjRmYi0Z"
      },
      "source": [
        "#### Definindo os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFd_xpT4YlkD"
      },
      "outputs": [],
      "source": [
        "def get_efficientnet_b0(num_classes=10):\n",
        "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "    if hasattr(model.classifier, 'in_features'):\n",
        "        in_features = model.classifier.in_features\n",
        "    elif hasattr(model.classifier, 'fc'):\n",
        "        in_features = model.classifier.fc.in_features\n",
        "    else:\n",
        "        in_features = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_mobilenet_v2(num_classes=10):\n",
        "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_resnet50(num_classes=10):\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_inception_v3(num_classes=10):\n",
        "    model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, aux_logits=True)\n",
        "    model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_vgg16(num_classes=10):\n",
        "    #model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
        "    #model = models.vgg13(weights=models.VGG13_Weights.IMAGENET1K_V1)\n",
        "    #model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "    model = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "    # Congelar as camadas convolucionais\n",
        "    #for param in model.features.parameters():\n",
        "    #    param.requires_grad = False\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    return model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-CfdRq2ZvoZ"
      },
      "source": [
        "#### Definição das funções do Método OACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XdxC0KSfZyu-"
      },
      "outputs": [],
      "source": [
        "metrics_a = [\"precision\", \"accuracy\", \"recall\"]\n",
        "metrics_c = [\"mtp\", \"tpi\", \"ms\"]\n",
        "epsilon = 1e-5 # Parâmetro da padronização para evitar divisão por zero\n",
        "### AHP Method ###\n",
        "weight_derivation = 'geometric' # 'mean'; 'geometric' or 'max_eigen'\n",
        "dataset = np.array([# Dataset for assertiveness metrics (P -> A -> R)\n",
        "  #P      A      R\n",
        "  [1  ,   5,     7   ],   #P\n",
        "  [1/5,   1,     3   ],   #A\n",
        "  [1/7,   1/3,   1   ],   #R\n",
        "])\n",
        "dataset = np.array([ # Dataset for cost metrics (MTP -> TPI -> MS)\n",
        "  #MTP    TPI    MS\n",
        "  [  1,     5,   7   ],   #MTP\n",
        "  [1/5,     1,   3   ],   #TPI\n",
        "  [1/7,   1/3,   1   ],   #MS\n",
        "])\n",
        "\n",
        "weights, rc = ahp_method(dataset, wd = weight_derivation)\n",
        "w1, w2, w3 = weights[0], weights[1], weights[2]\n",
        "wa = [w1, w2, w3] # Precision, Acuraccy, Recall\n",
        "wc = [w1, w2, w3] # MTP, TPI, MS\n",
        "\n",
        "def get_max_min_metrics(metrics_dict):\n",
        "    \"\"\"Calcula os máximos e mínimos das métricas de custo resultante do aquecimento dos modelos\"\"\"\n",
        "    metricas_custo = ['mtp', 'tpi', 'ms']\n",
        "\n",
        "    max_custo = {metrica: float('-inf') for metrica in metricas_custo}\n",
        "    min_custo = {metrica: float('inf') for metrica in metricas_custo}\n",
        "\n",
        "    for model_name, metrics in metrics_dict.items():\n",
        "        for metrica in metricas_custo:\n",
        "            valor = metrics[metrica]\n",
        "            if valor > max_custo[metrica]:\n",
        "                max_custo[metrica] = valor\n",
        "            if valor < min_custo[metrica]:\n",
        "                min_custo[metrica] = valor\n",
        "\n",
        "    # Convertendo os dicionários de máximos e mínimos em listas simples\n",
        "    max_custo_list = [max_custo[metrica] for metrica in metricas_custo]\n",
        "    min_custo_list = [min_custo[metrica] for metrica in metricas_custo]\n",
        "\n",
        "    return max_custo_list, min_custo_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def N(value, max_value, min_value):\n",
        "    \"\"\"Função de normalização min-max, com clamp para garantir valores entre 0 e 1 e logs para valores fora do intervalo.\"\"\"\n",
        "    if max_value is None or min_value is None or max_value == min_value:\n",
        "        return 0.0\n",
        "    normalized = (value - min_value) / (max_value - min_value)\n",
        "    return max(0.0, min(1.0, normalized))  # Clampa entre 0 e 1\n",
        "\n",
        "def N_cost(value, max_value, min_value):\n",
        "    if max_value is None or min_value is None or max_value == min_value:\n",
        "        return 0.0\n",
        "    normalized = (max_value - value) / (max_value - min_value)\n",
        "    return max(0.0, min(1.0, normalized))  \n",
        "\n",
        "def A(metrics, wa, metricas_a, maximos_a, minimos_a):\n",
        "    \"\"\"Calcula a assertividade normalizada.\"\"\"\n",
        "    a_i = [metrics['assertividade'][metrica] for metrica in metricas_a]\n",
        "    normalized_values = [N(a, maximo, minimo) for a, maximo, minimo in zip(a_i, maximos_a, minimos_a)]\n",
        "    return sum([n * w for n, w in zip(normalized_values, wa)])\n",
        "\n",
        "def C(metrics, wc, metricas_c, maximos_c, minimos_c):\n",
        "    \"\"\"Calcula o custo normalizado.\"\"\"\n",
        "    c_i = [metrics['custo'][metrica] for metrica in metricas_c]\n",
        "    normalized_values = [N_cost(c, maximo, minimo) for c, maximo, minimo in zip(c_i, maximos_c, minimos_c)]\n",
        "    return sum([n * w for n, w in zip(normalized_values, wc)])\n",
        "\n",
        "def F_score(lambda_, assertiveness, cost, max_score, min_score):\n",
        "    \"\"\"Calcula o score do método e normaliza.\"\"\"\n",
        "    score = lambda_ * assertiveness + (1 - lambda_) * cost\n",
        "    return N(score, max_score, min_score)\n",
        "\n",
        "def calculo_maximos_minimos(accumulated_metrics, metricas, tipo):\n",
        "    \"\"\"Calcula os máximos e mínimos para normalização das métricas.\"\"\"\n",
        "    if not accumulated_metrics:\n",
        "        return [0.0] * len(metricas), [0.0] * len(metricas)  # Valores padrão para evitar erros iniciais\n",
        "\n",
        "    valores = {metrica: [] for metrica in metricas}\n",
        "    for metrics in accumulated_metrics:\n",
        "        for metrica in metricas:\n",
        "            valores[metrica].append(float(metrics[tipo][metrica]))\n",
        "\n",
        "    maximos = [np.max(valores[metrica]) for metrica in metricas]\n",
        "    minimos = [np.min(valores[metrica]) for metrica in metricas]\n",
        "    return maximos, minimos\n",
        "\n",
        "def calcular_metricas_oace(iteration_metrics, accumulated_metrics, lambda_, wa, wc, metricas_a, metricas_c, maximos_a=None, minimos_a=None, maximos_c=None, minimos_c=None):\n",
        "    print(\"\\n🔎 INICIANDO A AVALIAÇÃO DO OACE PARA ITERAÇÃO ATUAL\")\n",
        "    print(\"iteration_metrics: \", iteration_metrics)\n",
        "    print(\"accumulated_metrics: \", accumulated_metrics)\n",
        "\n",
        "    if not iteration_metrics:\n",
        "        return None\n",
        "    if maximos_a is None or minimos_a is None:\n",
        "        maximos_a, minimos_a = calculo_maximos_minimos(accumulated_metrics, metricas_a, \"assertividade\")\n",
        "        \n",
        "    print(\"maximos_a: \", maximos_a)\n",
        "    print(\"minimos_a: \", minimos_a)\n",
        "    print(\"maximos_c (fixos do aquecimento): \", maximos_c)\n",
        "    print(\"minimos_c (fixos do aquecimento): \", minimos_c)\n",
        "\n",
        "    max_score = lambda_ * 1.0 + (1 - lambda_) * 1.0  # Máximo teórico\n",
        "    min_score = lambda_ * 0.0 + (1 - lambda_) * 0.0  # Mínimo teórico\n",
        "\n",
        "    assertividade = A(iteration_metrics, wa, metricas_a, maximos_a, minimos_a)\n",
        "    print(\"🔹 A (Assertividade Normalizada): \", assertividade)\n",
        "    custo = C(iteration_metrics, wc, metricas_c, maximos_c, minimos_c)\n",
        "    print(\"🔹 C (Custo Normalizado): \", custo)\n",
        "    score = F_score(lambda_, assertividade, custo, max_score, min_score)\n",
        "    print(\"🔹 S (Score OACE): \", score)\n",
        "\n",
        "    return {\n",
        "        \"model_name\": iteration_metrics[\"model_name\"],\n",
        "        \"A\": assertividade,\n",
        "        \"C\": custo,\n",
        "        \"Score\": score,\n",
        "        \"solution\": iteration_metrics[\"solution\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giVOsdD_aUZs"
      },
      "source": [
        "#### Código para hyperparametrização do método com random walk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmZ-joEyaWxG"
      },
      "source": [
        "Gerando as soluções com o random walk (alterar para configurar a semente random.seed())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hUTvmNeDaXn6"
      },
      "outputs": [],
      "source": [
        "def generate_solution(model_list):\n",
        "    \"\"\"Gera uma solução inicial para o Random Walk, em termos de taxa de aprendizado (lr) e modelo\"\"\"\n",
        "    lr = random.uniform(1e-4, 1e-2)\n",
        "    model_index = random.randint(0, len(model_list) - 1)  # Escolhe um modelo da lista\n",
        "    return [lr, model_index]\n",
        "\n",
        "def random_walk_step(solution, model_list, step_size=0.1):\n",
        "    \"\"\"Executa um passo do Random Walk para explorar novas soluções\"\"\"\n",
        "    new_solution = solution.copy()\n",
        "    new_solution[0] = min(max(new_solution[0] + random.uniform(-step_size * new_solution[0], step_size * new_solution[0]), 1e-4), 1e-2)\n",
        "    new_solution[1] = random.randint(0, len(model_list) - 1)  # Seleciona outro modelo aleatoriamente\n",
        "    return new_solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMWtdA00wpgu"
      },
      "source": [
        "Funções para treinamento e validação dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "H2tgn4eQwnWk"
      },
      "outputs": [],
      "source": [
        "def train_models(model, trainLoader, validLoader, criterion, optimizer, epochs=30, early_stopping_rounds=5):\n",
        "    \"\"\"Treina o modelo e monitora a perda de validação para aplicar early stopping.\"\"\"\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_count = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        model.train()\n",
        "        for data, target in trainLoader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Redimensionamento dinâmico se necessário\n",
        "            if isinstance(model, models.Inception3):\n",
        "                data = F.interpolate(data, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "\n",
        "            # Verifica se a saída é do tipo InceptionOutputs\n",
        "            if isinstance(output, InceptionOutputs):\n",
        "                output = output.logits  # Usa apenas a saída principal\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in validLoader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                 # Redimensionamento dinâmico se necessário\n",
        "                if isinstance(model, models.Inception3):\n",
        "                    data = F.interpolate(data, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "                output = model(data)\n",
        "                # Verifica se a saída é do tipo InceptionOutputs\n",
        "                if isinstance(output, InceptionOutputs):\n",
        "                    output = output.logits  # Usa apenas a saída principal\n",
        "                loss = criterion(output, target)\n",
        "                valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(trainLoader.dataset)\n",
        "        valid_loss = valid_loss/len(validLoader.dataset)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "\n",
        "        if valid_loss < best_val_loss:\n",
        "            best_val_loss = valid_loss\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "\n",
        "        if no_improvement_count >= early_stopping_rounds:\n",
        "            print(f\"Early stopping after {epoch} epochs due to no improvement.\")\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_solution(model, trainLoader, testLoader, validLoader, criterion, optimizer, dataset_name):\n",
        "    \"\"\"\n",
        "    - Avalia uma solução de modelo treinado medindo sua precisão, acurácia, recall, tempo de inferência, tamanho e número de parâmetros.\n",
        "    - Esta função treina o modelo, realiza inferências no conjunto de testes e calcula várias métricas de desempenho, incluindo assertividade e custo computacional.\n",
        "    \"\"\"\n",
        "    model = train_models(model, trainLoader, validLoader, criterion, optimizer)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, target in testLoader:\n",
        "            inputs, target = inputs.to(device), target.to(device)\n",
        "\n",
        "            # Redimensionamento dinâmico se necessário\n",
        "            if isinstance(model, models.Inception3):\n",
        "                inputs = F.interpolate(inputs, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            inference_time = time.time() - start_time\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(target.cpu().numpy())\n",
        "            inference_times.append(inference_time)\n",
        "\n",
        "    # Defina o valor de 'average' com base no tipo de dataset\n",
        "    if dataset_name == \"Chest X-Ray\":\n",
        "        average_type = 'binary'\n",
        "    else:\n",
        "        average_type = 'macro'\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, average=average_type, zero_division=0)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds, average=average_type, zero_division=0)# No dataset char x-ray average binary deve ser utilizada, para o restanto, micro ou average\n",
        "\n",
        "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
        "    num_params = sum(p.numel() for p in model.parameters()) \n",
        "    model_size = sum(p.element_size() * p.numel() for p in model.parameters()) / (1024 ** 2)\n",
        "\n",
        "    return float(precision), accuracy, float(recall), avg_inference_time, model_size, num_params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Função para Aquecimento dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warm_calculate_metrics(model, dataloader, device):\n",
        "    \"\"\"Calcula as métricas de custo no aquecimento para um modelo dado\"\"\"\n",
        "    model.eval()\n",
        "    total_inference_time = 0.0\n",
        "\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, target in dataloader:\n",
        "            inputs, target = inputs.to(device), target.to(device)\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            inference_time = time.time() - start_time\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            inference_times.append(inference_time)\n",
        "\n",
        "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    model_size = sum(p.element_size() * p.numel() for p in model.parameters()) / (1024**2)  # Size in MB\n",
        "\n",
        "    return num_params, avg_inference_time, model_size\n",
        "\n",
        "def warm_up_models(models, dataloader, device):\n",
        "    metrics = {}\n",
        "    for model_name, get_model_func in models:\n",
        "        model = get_model_func().to(device)\n",
        "        num_params, avg_inference_time, model_size = warm_calculate_metrics(model, dataloader, device)\n",
        "        metrics[model_name] = {\n",
        "            'mtp': num_params,\n",
        "            'tpi': avg_inference_time,\n",
        "            'ms': model_size\n",
        "        }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(current_round, iteration, best_model_overall, best_score_overall, best_solution_overall,\n",
        "                    metrics_per_iteration, oace_metrics_per_iteration, max_assertiveness_max, max_assertiveness_min, checkpoint_path):\n",
        "    \"\"\"Salva o estado atual do treinamento para continuar depois.\"\"\"\n",
        "    checkpoint_data = {\n",
        "        'current_round': current_round,\n",
        "        'iteration': iteration,\n",
        "        'best_model_overall': best_model_overall,\n",
        "        'best_score_overall': best_score_overall,\n",
        "        'best_solution_overall': best_solution_overall,\n",
        "        'metrics_per_iteration': metrics_per_iteration,  # Armazena todas as iterações\n",
        "        'oace_metrics_per_iteration': oace_metrics_per_iteration,  # Armazena todas as métricas OACE\n",
        "        'max_assertiveness_max': max_assertiveness_max,\n",
        "        'max_assertiveness_min': max_assertiveness_min\n",
        "    }\n",
        "    with open(checkpoint_path, 'wb') as f:\n",
        "        pickle.dump(checkpoint_data, f)\n",
        "    print(f\"✅ Checkpoint salvo na Rodada {current_round + 1}, Iteração {iteration + 1}.\")\n",
        "\n",
        "def load_checkpoint(checkpoint_path):\n",
        "    \"\"\"Carrega o checkpoint, se existir.\"\"\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        with open(checkpoint_path, 'rb') as f:\n",
        "            checkpoint = pickle.load(f)\n",
        "        return checkpoint\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwAUnOIma9uK"
      },
      "source": [
        "Função principal para execução do método (alterar para ajustar para nova metodologia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_hyperparameters(models_list, trainloader, testloader, validLoader, classes, lbd, wa, wc, dataset_name, checkpoint_path, num_rounds=3, iterations_per_round=10, save_checkpoint_every=5):\n",
        "    \n",
        "    initial_seeds = [100, 600, 1100]  # Seeds fixas, pode ser [50, 150, 200], [100, 600, 1100] ou [1000, 2500, 4000]\n",
        "\n",
        "    checkpoint = load_checkpoint(checkpoint_path)\n",
        "    if checkpoint:\n",
        "        current_round = checkpoint['current_round']\n",
        "        iteration = checkpoint['iteration']\n",
        "        best_model_overall = checkpoint['best_model_overall']\n",
        "        best_score_overall = checkpoint['best_score_overall']\n",
        "        best_solution_overall = checkpoint['best_solution_overall']\n",
        "        metrics_per_iteration = checkpoint['metrics_per_iteration']  \n",
        "        oace_metrics_per_iteration = checkpoint['oace_metrics_per_iteration']  \n",
        "        maximos_a = checkpoint['max_assertiveness_max']  \n",
        "        minimos_a = checkpoint['max_assertiveness_min']  \n",
        "\n",
        "        print(f\"🔄 Continuação do treinamento a partir da Rodada {current_round + 1}, Iteração {iteration + 1}...\")\n",
        "    else:\n",
        "        current_round = 0\n",
        "        iteration = 0  \n",
        "        best_model_overall = None\n",
        "        best_score_overall = float('-inf')\n",
        "        best_solution_overall = None\n",
        "        metrics_per_iteration = {}  # Dicionário para todas as iterações\n",
        "        oace_metrics_per_iteration = {}  # Dicionário para todas as métricas OACE\n",
        "        maximos_a, minimos_a = None, None  # Inicia como None para recalcular ou carregar do checkpoint\n",
        "\n",
        "    with open('warm_up_metrics.pkl', 'rb') as f:\n",
        "        warm_up_metrics = pickle.load(f)\n",
        "\n",
        "    maximos_c, minimos_c = get_max_min_metrics(warm_up_metrics)\n",
        "\n",
        "    accumulated_metrics = []  # Para calcular máximos/mínimos de assertividade\n",
        "    total_iterations = num_rounds * iterations_per_round  # Total de iterações globais\n",
        "\n",
        "    for round_idx in range(current_round, num_rounds):\n",
        "        print(f\"\\n🔄 Iniciando Rodada {round_idx + 1}/{num_rounds} 🔄\")\n",
        "        base_seed = initial_seeds[round_idx] \n",
        "        best_model = None\n",
        "        best_score = float('-inf')\n",
        "        best_solution = None if not checkpoint or round_idx > current_round else best_solution_overall\n",
        "\n",
        "        # Reinicia a solução se for um novo round após o checkpoint\n",
        "        if round_idx > current_round or not checkpoint:\n",
        "            solution = generate_solution(models_list)\n",
        "        else:\n",
        "            solution = best_solution_overall\n",
        "\n",
        "        # Itera sobre as iterações desta rodada, incrementando a seed\n",
        "        for local_iteration in range(iterations_per_round):\n",
        "            global_iteration = round_idx * iterations_per_round + local_iteration  # Iteração global\n",
        "            if global_iteration <= iteration and checkpoint:  # Pula iterações já processadas\n",
        "                continue\n",
        "\n",
        "            current_seed = base_seed + local_iteration  # Incrementa a seed dentro do round\n",
        "            random.seed(current_seed)\n",
        "\n",
        "            print(f\"▶️ Iteration {global_iteration + 1}/{total_iterations} (Round {round_idx + 1}): model {solution[1]} e lr {solution[0]}\")\n",
        "            print(f\"🔀 Random Seed Atual: {current_seed}\")\n",
        "\n",
        "            model_name, Model = models_list[solution[1]]\n",
        "            model = Model(num_classes=len(classes)).to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=solution[0])\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            precision, accuracy, recall, avg_inference_time, model_size, num_params = evaluate_solution(\n",
        "                model, trainloader, testloader, validLoader, criterion, optimizer, dataset_name)\n",
        "\n",
        "            current_metrics = {\n",
        "                \"model_name\": model_name,\n",
        "                \"assertividade\": {\"precision\": precision, \"accuracy\": accuracy, \"recall\": recall},\n",
        "                \"custo\": {\"mtp\": num_params, \"tpi\": avg_inference_time, \"ms\": model_size},\n",
        "                \"solution\": {\"lr\": solution[0], \"model_index\": solution[1]}\n",
        "            }\n",
        "\n",
        "            accumulated_metrics.append(current_metrics)\n",
        "            metrics_per_iteration[global_iteration] = current_metrics\n",
        "\n",
        "            # Calcular OACE usando os custos fixos do aquecimento e os máximos/mínimos de assertividade carregados ou atualizados\n",
        "            oace_metrics = calcular_metricas_oace(\n",
        "                current_metrics,\n",
        "                accumulated_metrics,\n",
        "                lbd, wa, wc,\n",
        "                [\"precision\", \"accuracy\", \"recall\"],\n",
        "                [\"mtp\", \"tpi\", \"ms\"],\n",
        "                maximos_a, minimos_a,\n",
        "                maximos_c, minimos_c\n",
        "            )\n",
        "            oace_metrics_per_iteration[global_iteration] = oace_metrics\n",
        "\n",
        "            print(\"Resultado do OACE por Iteração: \", oace_metrics)\n",
        "            score = oace_metrics[\"Score\"]\n",
        "\n",
        "            # Atualizar o melhor modelo globalmente (sobre todas as iterações)\n",
        "            if score > best_score_overall:\n",
        "                best_score_overall = score\n",
        "                best_model_overall = model_name\n",
        "                best_solution_overall = solution.copy()\n",
        "\n",
        "            solution = random_walk_step(solution, models_list)\n",
        "\n",
        "            # Salvar checkpoint a cada 'save_checkpoint_every' iterações globais\n",
        "            if (global_iteration + 1) % save_checkpoint_every == 0 or global_iteration == total_iterations - 1:\n",
        "                save_checkpoint(\n",
        "                    round_idx, global_iteration, best_model_overall, best_score_overall, best_solution_overall,\n",
        "                    metrics_per_iteration, oace_metrics_per_iteration, maximos_a, minimos_a, checkpoint_path\n",
        "                )\n",
        "\n",
        "        # Atualizar máximos e mínimos de assertividade ao final de cada round\n",
        "        current_max_a, current_min_a = calculo_maximos_minimos(accumulated_metrics, [\"precision\", \"accuracy\", \"recall\"], \"assertividade\")\n",
        "        if maximos_a is None or minimos_a is None:\n",
        "            maximos_a, minimos_a = current_max_a, current_min_a\n",
        "        else:\n",
        "            for i in range(len(current_max_a)):\n",
        "                maximos_a[i] = max(maximos_a[i], current_max_a[i])\n",
        "                minimos_a[i] = min(minimos_a[i], current_min_a[i])\n",
        "\n",
        "    return best_model_overall, best_score_overall, best_solution_overall, metrics_per_iteration, oace_metrics_per_iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxXHsRrxcqp"
      },
      "source": [
        "Código principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iFGsEK4_O0Gp"
      },
      "outputs": [],
      "source": [
        "datasets_options = {\n",
        "        '1': 'Chest X-Ray',\n",
        "        '2': 'CIFAR-10',\n",
        "        '3': 'TrashNet'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHXpibmGxjD_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#train_dir = '/content/drive/MyDrive/Método OACE/datasets/chest_xray/train'\n",
        "#val_dir = '/content/drive/MyDrive/Método OACE/datasets/chest_xray/val'\n",
        "#test_dir = '/content/drive/MyDrive/Método OACE/datasets/chest_xray/test'\n",
        "#lbd = 0.75\n",
        "#trainLoader, validLoader, testLoader, classes = chest_x_ray(train_dir, val_dir, test_dir)\n",
        "\n",
        "#subsample_loader, subsample_classes = chest_x_ray_subsample(test_dir)\n",
        "################################################################################\n",
        "# CIFAR-10\n",
        "lbd = 0.5\n",
        "trainLoader, validLoader, testLoader, classes = cifar_10(batch_size=64)\n",
        "dataset_name = datasets_options['2']\n",
        "#subsample_loader, subsample_classes = cifar_10_subsample()\n",
        "################################################################################\n",
        "# TrashNet\n",
        "#lbd = 0.25\n",
        "#dataset_dir = 'datasets/dataset-resized'\n",
        "#trainLoader, validLoader, testLoader, classes = trashNet(dataset_dir)\n",
        "#ataset_name = datasets_options['3']\n",
        "#subsample_loader, subsample_classes = trashNet_subsample(dataset_dir)\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "625"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEAY3DdkXlv3",
        "outputId": "d6b1b908-3905-4390-8933-e670b80d7823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch de imagens shape: torch.Size([64, 3, 32, 32])\n",
            "Batch de rótulos shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in trainLoader:\n",
        "    print(f\"Batch de imagens shape: {images.shape}\")\n",
        "    print(f\"Batch de rótulos shape: {labels.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "gcVeh31uxn-9",
        "outputId": "b22e60c5-d131-4378-e894-0cb62e49435c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFORMAÇÕES SOBRE O AMBIENTE DE EXECUÇÃO:\n",
            "PyTorch version: 2.3.1+cu121\n",
            "CUDA available: True\n",
            "CUDA version: 12.1\n",
            "Number of GPUs: 1\n",
            "Current GPU: 0\n",
            "GPU name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
            "\n",
            "Iniciando o aquecimento dos modelos...\n",
            "\n",
            "Classes dos dados para aquecimento: ['glass', 'plastic']\n",
            "Batch de imagens shape: torch.Size([16, 3, 224, 224])\n",
            "Batch de rótulos shape: torch.Size([16])\n",
            "Warm-up concluído e métricas salvas.\n"
          ]
        }
      ],
      "source": [
        "models_list = [\n",
        "    (\"EfficientNetB0\", get_efficientnet_b0),\n",
        "    (\"MobileNetV2\", get_mobilenet_v2),\n",
        "    (\"ResNet50\", get_resnet50),\n",
        "    (\"InceptionV3\", get_inception_v3),\n",
        "    (\"VGG16\", get_vgg16)\n",
        "]\n",
        "\n",
        "wa = [0.731, 0.188, 0.081]  # Pesos para Precision, Accuracy, Recall\n",
        "wc = [0.731, 0.188, 0.081]  # Pesos para MTP, TPI, MS\n",
        "\n",
        "print(\"INFORMAÇÕES SOBRE O AMBIENTE DE EXECUÇÃO:\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
        "\n",
        "print(\"\\nIniciando o aquecimento dos modelos...\\n\")\n",
        "subsample_loader, subsample_classes = cifar_10_subsample()  # Atualize para o caminho correto\n",
        "print(\"Classes dos dados para aquecimento:\", subsample_classes)\n",
        "for images, labels in subsample_loader:\n",
        "    print(f\"Batch de imagens shape: {images.shape}\")\n",
        "    print(f\"Batch de rótulos shape: {labels.shape}\")\n",
        "    break\n",
        "warm_up_metrics = warm_up_models(models_list, subsample_loader, device)\n",
        "with open('warm_up_metrics.pkl', 'wb') as f:\n",
        "    pickle.dump(warm_up_metrics, f)\n",
        "    \n",
        "print(\"Warm-up concluído e métricas salvas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Iniciando Rodada 1/3 🔄\n",
            "▶️ Iteration 1/15 (Round 1): model 1 e lr 0.0015668949432321277\n",
            "🔀 Random Seed Atual: 100\n",
            "Epoch: 1 \tTraining Loss: 1.433616 \tValidation Loss: 0.326847\n",
            "Epoch: 2 \tTraining Loss: 1.197285 \tValidation Loss: 0.263113\n",
            "Epoch: 3 \tTraining Loss: 0.983905 \tValidation Loss: 0.431060\n",
            "Epoch: 4 \tTraining Loss: 0.962569 \tValidation Loss: 0.336314\n",
            "Epoch: 5 \tTraining Loss: 0.900942 \tValidation Loss: 0.252637\n",
            "Epoch: 6 \tTraining Loss: 0.789127 \tValidation Loss: 0.228569\n",
            "Epoch: 7 \tTraining Loss: 0.718747 \tValidation Loss: 0.149641\n",
            "Epoch: 8 \tTraining Loss: 0.696015 \tValidation Loss: 0.144554\n",
            "Epoch: 9 \tTraining Loss: 0.771429 \tValidation Loss: 0.179300\n",
            "Epoch: 10 \tTraining Loss: 1.031334 \tValidation Loss: 0.270777\n",
            "Epoch: 11 \tTraining Loss: 0.859582 \tValidation Loss: 0.224003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000019E93FCA660>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Lyanh\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"C:\\Users\\Lyanh\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1437, in _shutdown_workers\n",
            "    if self._persistent_workers or self._workers_status[worker_id]:\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12 \tTraining Loss: 0.699431 \tValidation Loss: 0.139094\n",
            "Epoch: 13 \tTraining Loss: 0.647175 \tValidation Loss: 0.145645\n",
            "Epoch: 14 \tTraining Loss: 0.591448 \tValidation Loss: 0.299325\n",
            "Epoch: 15 \tTraining Loss: 1.250400 \tValidation Loss: 0.251481\n",
            "Epoch: 16 \tTraining Loss: 0.859407 \tValidation Loss: 0.199170\n",
            "Epoch: 17 \tTraining Loss: 0.695167 \tValidation Loss: 0.159630\n",
            "Early stopping after 17 epochs due to no improvement.\n",
            "\n",
            "🔎 INICIANDO A AVALIAÇÃO DO OACE PARA ITERAÇÃO ATUAL\n",
            "iteration_metrics:  {'model_name': 'VGG16', 'assertividade': {'precision': 0.7618229307836331, 'accuracy': 0.7569, 'recall': 0.7569000000000001}, 'custo': {'mtp': 134309962, 'tpi': 0.06843847226185404, 'ms': 512.3518447875977}, 'solution': {'lr': 0.0015668949432321277, 'model_index': 1}}\n",
            "accumulated_metrics:  [{'model_name': 'VGG16', 'assertividade': {'precision': 0.7618229307836331, 'accuracy': 0.7569, 'recall': 0.7569000000000001}, 'custo': {'mtp': 134309962, 'tpi': 0.06843847226185404, 'ms': 512.3518447875977}, 'solution': {'lr': 0.0015668949432321277, 'model_index': 1}}]\n",
            "maximos_a:  [0.7618229307836331, 0.7569, 0.7569000000000001]\n",
            "minimos_a:  [0.7618229307836331, 0.7569, 0.7569000000000001]\n",
            "maximos_c (fixos do aquecimento):  [134309962, 0.02737882060389365, 512.3518447875977]\n",
            "minimos_c (fixos do aquecimento):  [24371444, 0.004024182596514302, 92.96968078613281]\n",
            "🔹 A (Assertividade Normalizada):  0.0\n",
            "🔹 C (Custo Normalizado):  0.0\n",
            "🔹 S (Score OACE):  0.0\n",
            "Resultado do OACE por Iteração:  {'model_name': 'VGG16', 'A': 0.0, 'C': 0.0, 'Score': 0.0, 'solution': {'lr': 0.0015668949432321277, 'model_index': 1}}\n",
            "▶️ Iteration 2/15 (Round 1): model 1 e lr 0.0014558551327503255\n",
            "🔀 Random Seed Atual: 101\n",
            "Epoch: 1 \tTraining Loss: 1.318665 \tValidation Loss: 0.426459\n",
            "Epoch: 2 \tTraining Loss: 1.046726 \tValidation Loss: 0.268672\n",
            "Epoch: 3 \tTraining Loss: 0.886627 \tValidation Loss: 0.185235\n",
            "Epoch: 4 \tTraining Loss: 0.819273 \tValidation Loss: 0.188056\n",
            "Epoch: 5 \tTraining Loss: 0.754383 \tValidation Loss: 0.217344\n",
            "Epoch: 6 \tTraining Loss: 0.758471 \tValidation Loss: 0.176307\n",
            "Epoch: 7 \tTraining Loss: 0.767261 \tValidation Loss: 0.170468\n",
            "Epoch: 8 \tTraining Loss: 0.795551 \tValidation Loss: 0.226081\n",
            "Epoch: 9 \tTraining Loss: 1.160596 \tValidation Loss: 0.235427\n",
            "Epoch: 10 \tTraining Loss: 0.816259 \tValidation Loss: 0.163398\n",
            "Epoch: 11 \tTraining Loss: 0.728811 \tValidation Loss: 0.222913\n",
            "Epoch: 12 \tTraining Loss: 0.658074 \tValidation Loss: 0.172117\n",
            "Epoch: 13 \tTraining Loss: 0.583035 \tValidation Loss: 0.194690\n",
            "Epoch: 14 \tTraining Loss: 0.643328 \tValidation Loss: 0.207362\n",
            "Epoch: 15 \tTraining Loss: 0.645473 \tValidation Loss: 0.158343\n",
            "Epoch: 16 \tTraining Loss: 0.624430 \tValidation Loss: 0.229201\n",
            "Epoch: 17 \tTraining Loss: 0.659495 \tValidation Loss: 0.151667\n",
            "Epoch: 18 \tTraining Loss: 0.827482 \tValidation Loss: 0.265079\n",
            "Epoch: 19 \tTraining Loss: 0.754660 \tValidation Loss: 0.140073\n",
            "Epoch: 20 \tTraining Loss: 0.561261 \tValidation Loss: 0.150237\n",
            "Epoch: 21 \tTraining Loss: 0.487528 \tValidation Loss: 0.221773\n",
            "Epoch: 22 \tTraining Loss: 0.490732 \tValidation Loss: 0.133216\n",
            "Epoch: 23 \tTraining Loss: 0.430663 \tValidation Loss: 0.160467\n",
            "Epoch: 24 \tTraining Loss: 0.448668 \tValidation Loss: 0.114053\n",
            "Epoch: 25 \tTraining Loss: 0.419687 \tValidation Loss: 0.106620\n",
            "Epoch: 26 \tTraining Loss: 0.493801 \tValidation Loss: 0.133046\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m best_model, best_score, best_solution, metrics, oace_metrics \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations_per_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43msave_checkpoint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[31], line 66\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(models_list, trainloader, testloader, validLoader, classes, lbd, wa, wc, dataset_name, checkpoint_path, num_rounds, iterations_per_round, save_checkpoint_every)\u001b[0m\n\u001b[0;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39msolution[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     64\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 66\u001b[0m precision, accuracy, recall, avg_inference_time, model_size, num_params \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_solution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m current_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertividade\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall},\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcusto\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmtp\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_params, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtpi\u001b[39m\u001b[38;5;124m\"\u001b[39m: avg_inference_time, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_size},\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: solution[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: solution[\u001b[38;5;241m1\u001b[39m]}\n\u001b[0;32m     74\u001b[0m }\n\u001b[0;32m     76\u001b[0m accumulated_metrics\u001b[38;5;241m.\u001b[39mappend(current_metrics)\n",
            "Cell \u001b[1;32mIn[37], line 71\u001b[0m, in \u001b[0;36mevaluate_solution\u001b[1;34m(model, trainLoader, testLoader, validLoader, criterion, optimizer, dataset_name)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_solution\u001b[39m(model, trainLoader, testLoader, validLoader, criterion, optimizer, dataset_name):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    - Avalia uma solução de modelo treinado medindo sua precisão, acurácia, recall, tempo de inferência, tamanho e número de parâmetros.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    - Esta função treina o modelo, realiza inferências no conjunto de testes e calcula várias métricas de desempenho, incluindo assertividade e custo computacional.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     73\u001b[0m     all_preds \u001b[38;5;241m=\u001b[39m []\n",
            "Cell \u001b[1;32mIn[37], line 29\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(model, trainLoader, validLoader, criterion, optimizer, epochs, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 29\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"checkpoint.pkl\"\n",
        "best_model, best_score, best_solution, metrics, oace_metrics = optimize_hyperparameters(models_list, \n",
        "                                                                                        trainLoader, testLoader, validLoader, \n",
        "                                                                                        classes, lbd, wa, wc,\n",
        "                                                                                        dataset_name, checkpoint_path, \n",
        "                                                                                        num_rounds=3, iterations_per_round=5, \n",
        "                                                                                        save_checkpoint_every=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4tlP5z7xyQr",
        "outputId": "ab3c1e58-9cc0-4f24-824f-8a7acd72d48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model: MobileNetV2\n",
            "Best Score: 0.9355926436048008\n",
            "Best Solution: [0.004915491436617374, 1]\n",
            "ML Metrics: {0: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.3931453671403046, 'accuracy': 0.40476190476190477, 'recall': 0.36750230069305684}, 'custo': {'mtp': 4015234, 'tpi': 0.03408905863761902, 'ms': 15.316902160644531}, 'solution': {'lr': 0.008173306304572338, 'model_index': 0}}, 1: {'model_name': 'ResNet50', 'assertividade': {'precision': 0.3096171802054155, 'accuracy': 0.23015873015873015, 'recall': 0.1788377965703547}, 'custo': {'mtp': 23520326, 'tpi': 0.09884101152420044, 'ms': 89.7229232788086}, 'solution': {'lr': 0.008169279428953099, 'model_index': 2}}, 2: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.23508678539166347, 'accuracy': 0.3373015873015873, 'recall': 0.29257386810470737}, 'custo': {'mtp': 2231558, 'tpi': 0.04945465922355652, 'ms': 8.512718200683594}, 'solution': {'lr': 0.007750224415955002, 'model_index': 1}}, 3: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.3657045830741368, 'accuracy': 0.3412698412698413, 'recall': 0.35750674350336425}, 'custo': {'mtp': 4015234, 'tpi': 0.0594521164894104, 'ms': 15.316902160644531}, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 4: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.2953035336756267, 'accuracy': 0.39285714285714285, 'recall': 0.3297560983148498}, 'custo': {'mtp': 2231558, 'tpi': 0.0539628267288208, 'ms': 8.512718200683594}, 'solution': {'lr': 0.008690641876341252, 'model_index': 1}}, 5: {'model_name': 'ResNet50', 'assertividade': {'precision': 0.3861642065767583, 'accuracy': 0.44841269841269843, 'recall': 0.3872651465428593}, 'custo': {'mtp': 23520326, 'tpi': 0.09154194593429565, 'ms': 89.7229232788086}, 'solution': {'lr': 0.0044454829886935235, 'model_index': 2}}, 6: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.3899265019586549, 'accuracy': 0.4365079365079365, 'recall': 0.3862370646489373}, 'custo': {'mtp': 4015234, 'tpi': 0.05218648910522461, 'ms': 15.316902160644531}, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 7: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.16479010286349735, 'accuracy': 0.32142857142857145, 'recall': 0.2596899224806202}, 'custo': {'mtp': 2231558, 'tpi': 0.049702465534210205, 'ms': 8.512718200683594}, 'solution': {'lr': 0.008842528185337765, 'model_index': 1}}, 8: {'model_name': 'InceptionV3', 'assertividade': {'precision': 0.04453142727479011, 'accuracy': 0.17857142857142858, 'recall': 0.16164505466564963}, 'custo': {'mtp': 24360172, 'tpi': 0.12567037343978882, 'ms': 92.92668151855469}, 'solution': {'lr': 0.009687260779252884, 'model_index': 3}}, 9: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.24894179894179894, 'accuracy': 0.1349206349206349, 'recall': 0.19528593771249833}, 'custo': {'mtp': 4015234, 'tpi': 0.07633677124977112, 'ms': 15.316902160644531}, 'solution': {'lr': 0.01, 'model_index': 0}}, 10: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.5323183760683761, 'accuracy': 0.4642857142857143, 'recall': 0.3785463799293558}, 'custo': {'mtp': 2231558, 'tpi': 0.04039457440376282, 'ms': 8.512718200683594}, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 11: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.44737176869197487, 'accuracy': 0.4603174603174603, 'recall': 0.4274335742072956}, 'custo': {'mtp': 2231558, 'tpi': 0.05407071113586426, 'ms': 8.512718200683594}, 'solution': {'lr': 0.004468780719721807, 'model_index': 1}}, 12: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.4513536987121893, 'accuracy': 0.4880952380952381, 'recall': 0.4333709413328646}, 'custo': {'mtp': 2231558, 'tpi': 0.056870877742767334, 'ms': 8.512718200683594}, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 13: {'model_name': 'InceptionV3', 'assertividade': {'precision': 0.11150793650793651, 'accuracy': 0.32142857142857145, 'recall': 0.24088250930356195}, 'custo': {'mtp': 24360172, 'tpi': 0.6650974750518799, 'ms': 92.92668151855469}, 'solution': {'lr': 0.005174912960528561, 'model_index': 3}}, 14: {'model_name': 'InceptionV3', 'assertividade': {'precision': 0.32210129772629775, 'accuracy': 0.24603174603174602, 'recall': 0.27521919745590656}, 'custo': {'mtp': 24360172, 'tpi': 0.6177894771099091, 'ms': 92.92668151855469}, 'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}\n",
            "OACE Metrics: {0: {'model_name': 'EfficientNetB0', 'A': 0.0, 'C': 0.746754924222813, 'Score': 0.5600661931671097, 'solution': {'lr': 0.008173306304572338, 'model_index': 0}}, 1: {'model_name': 'ResNet50', 'A': 0.0, 'C': 0.031222735351751237, 'Score': 0.023417051513813427, 'solution': {'lr': 0.008169279428953099, 'model_index': 2}}, 2: {'model_name': 'MobileNetV2', 'A': 0.16419434692639776, 'C': 0.8119999999999999, 'Score': 0.6500485867315994, 'solution': {'lr': 0.007750224415955002, 'model_index': 1}}, 3: {'model_name': 'EfficientNetB0', 'A': 0.8004349448738249, 'C': 0.746754924222813, 'Score': 0.760174929385566, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 4: {'model_name': 'MobileNetV2', 'A': 0.5184705903013165, 'C': 0.8119999999999999, 'Score': 0.7386176475753291, 'solution': {'lr': 0.008690641876341252, 'model_index': 1}}, 5: {'model_name': 'ResNet50', 'A': 1.0231979099304807, 'C': 0.031222735351751237, 'Score': 0.27921652899643357, 'solution': {'lr': 0.0044454829886935235, 'model_index': 2}}, 6: {'model_name': 'EfficientNetB0', 'A': 1.0273384557591472, 'C': 0.746754924222813, 'Score': 0.8169008071068965, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 7: {'model_name': 'MobileNetV2', 'A': -0.19212758639777694, 'C': 0.8119999999999999, 'Score': 0.5609681034005558, 'solution': {'lr': 0.008842528185337765, 'model_index': 1}}, 8: {'model_name': 'InceptionV3', 'A': -0.9442201606691986, 'C': 0.0004135063209624752, 'Score': -0.23574491042657778, 'solution': {'lr': 0.009687260779252884, 'model_index': 3}}, 9: {'model_name': 'EfficientNetB0', 'A': -0.03140611376185065, 'C': 0.746754924222813, 'Score': 0.552214664726647, 'solution': {'lr': 0.01, 'model_index': 0}}, 10: {'model_name': 'MobileNetV2', 'A': 1.3063705744192033, 'C': 0.8119999999999999, 'Score': 0.9355926436048008, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 11: {'model_name': 'MobileNetV2', 'A': 1.1434057982638959, 'C': 0.8119999999999999, 'Score': 0.894851449565974, 'solution': {'lr': 0.004468780719721807, 'model_index': 1}}, 12: {'model_name': 'MobileNetV2', 'A': 1.0, 'C': 0.8119999999999999, 'Score': 0.859, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 13: {'model_name': 'InceptionV3', 'A': 0.2852818560978563, 'C': 0.0004135063209624752, 'Score': 0.07163059376518592, 'solution': {'lr': 0.005174912960528561, 'model_index': 3}}, 14: {'model_name': 'InceptionV3', 'A': 0.6922535607954682, 'C': 0.0004135063209624752, 'Score': 0.1733735199395889, 'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}\n",
            "Método Finalizado: \n"
          ]
        }
      ],
      "source": [
        "print(f\"Best Model: {best_model}\")\n",
        "print(f\"Best Score: {best_score}\")\n",
        "print(f\"Best Solution: {best_solution}\")\n",
        "print(f\"ML Metrics: {metrics}\")\n",
        "print(f\"OACE Metrics: {oace_metrics}\")\n",
        "print(f\"Método Finalizado: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FeaJBg11F_t",
        "outputId": "fbb585b9-0e77-4b43-e974-b6914b28379f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.3931453671403046,\n",
              "   'accuracy': 0.40476190476190477,\n",
              "   'recall': 0.36750230069305684},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.03408905863761902,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.008173306304572338, 'model_index': 0}},\n",
              " 1: {'model_name': 'ResNet50',\n",
              "  'assertividade': {'precision': 0.3096171802054155,\n",
              "   'accuracy': 0.23015873015873015,\n",
              "   'recall': 0.1788377965703547},\n",
              "  'custo': {'mtp': 23520326,\n",
              "   'tpi': 0.09884101152420044,\n",
              "   'ms': 89.7229232788086},\n",
              "  'solution': {'lr': 0.008169279428953099, 'model_index': 2}},\n",
              " 2: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.23508678539166347,\n",
              "   'accuracy': 0.3373015873015873,\n",
              "   'recall': 0.29257386810470737},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.04945465922355652,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.007750224415955002, 'model_index': 1}},\n",
              " 3: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.3657045830741368,\n",
              "   'accuracy': 0.3412698412698413,\n",
              "   'recall': 0.35750674350336425},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.0594521164894104,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 4: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.2953035336756267,\n",
              "   'accuracy': 0.39285714285714285,\n",
              "   'recall': 0.3297560983148498},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.0539628267288208,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.008690641876341252, 'model_index': 1}},\n",
              " 5: {'model_name': 'ResNet50',\n",
              "  'assertividade': {'precision': 0.3861642065767583,\n",
              "   'accuracy': 0.44841269841269843,\n",
              "   'recall': 0.3872651465428593},\n",
              "  'custo': {'mtp': 23520326,\n",
              "   'tpi': 0.09154194593429565,\n",
              "   'ms': 89.7229232788086},\n",
              "  'solution': {'lr': 0.0044454829886935235, 'model_index': 2}},\n",
              " 6: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.3899265019586549,\n",
              "   'accuracy': 0.4365079365079365,\n",
              "   'recall': 0.3862370646489373},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.05218648910522461,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 7: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.16479010286349735,\n",
              "   'accuracy': 0.32142857142857145,\n",
              "   'recall': 0.2596899224806202},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.049702465534210205,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.008842528185337765, 'model_index': 1}},\n",
              " 8: {'model_name': 'InceptionV3',\n",
              "  'assertividade': {'precision': 0.04453142727479011,\n",
              "   'accuracy': 0.17857142857142858,\n",
              "   'recall': 0.16164505466564963},\n",
              "  'custo': {'mtp': 24360172,\n",
              "   'tpi': 0.12567037343978882,\n",
              "   'ms': 92.92668151855469},\n",
              "  'solution': {'lr': 0.009687260779252884, 'model_index': 3}},\n",
              " 9: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.24894179894179894,\n",
              "   'accuracy': 0.1349206349206349,\n",
              "   'recall': 0.19528593771249833},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.07633677124977112,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.01, 'model_index': 0}},\n",
              " 10: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.5323183760683761,\n",
              "   'accuracy': 0.4642857142857143,\n",
              "   'recall': 0.3785463799293558},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.04039457440376282,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 11: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.44737176869197487,\n",
              "   'accuracy': 0.4603174603174603,\n",
              "   'recall': 0.4274335742072956},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.05407071113586426,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.004468780719721807, 'model_index': 1}},\n",
              " 12: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.4513536987121893,\n",
              "   'accuracy': 0.4880952380952381,\n",
              "   'recall': 0.4333709413328646},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.056870877742767334,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 13: {'model_name': 'InceptionV3',\n",
              "  'assertividade': {'precision': 0.11150793650793651,\n",
              "   'accuracy': 0.32142857142857145,\n",
              "   'recall': 0.24088250930356195},\n",
              "  'custo': {'mtp': 24360172,\n",
              "   'tpi': 0.6650974750518799,\n",
              "   'ms': 92.92668151855469},\n",
              "  'solution': {'lr': 0.005174912960528561, 'model_index': 3}},\n",
              " 14: {'model_name': 'InceptionV3',\n",
              "  'assertividade': {'precision': 0.32210129772629775,\n",
              "   'accuracy': 0.24603174603174602,\n",
              "   'recall': 0.27521919745590656},\n",
              "  'custo': {'mtp': 24360172,\n",
              "   'tpi': 0.6177894771099091,\n",
              "   'ms': 92.92668151855469},\n",
              "  'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir5FqvYqiZe5",
        "outputId": "36f216fd-cf78-4ece-8a2a-39d21d123fdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: {'model_name': 'EfficientNetB0',\n",
              "  'A': 0.0,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.5600661931671097,\n",
              "  'solution': {'lr': 0.008173306304572338, 'model_index': 0}},\n",
              " 1: {'model_name': 'ResNet50',\n",
              "  'A': 0.0,\n",
              "  'C': 0.031222735351751237,\n",
              "  'Score': 0.023417051513813427,\n",
              "  'solution': {'lr': 0.008169279428953099, 'model_index': 2}},\n",
              " 2: {'model_name': 'MobileNetV2',\n",
              "  'A': 0.16419434692639776,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.6500485867315994,\n",
              "  'solution': {'lr': 0.007750224415955002, 'model_index': 1}},\n",
              " 3: {'model_name': 'EfficientNetB0',\n",
              "  'A': 0.8004349448738249,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.760174929385566,\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 4: {'model_name': 'MobileNetV2',\n",
              "  'A': 0.5184705903013165,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.7386176475753291,\n",
              "  'solution': {'lr': 0.008690641876341252, 'model_index': 1}},\n",
              " 5: {'model_name': 'ResNet50',\n",
              "  'A': 1.0231979099304807,\n",
              "  'C': 0.031222735351751237,\n",
              "  'Score': 0.27921652899643357,\n",
              "  'solution': {'lr': 0.0044454829886935235, 'model_index': 2}},\n",
              " 6: {'model_name': 'EfficientNetB0',\n",
              "  'A': 1.0273384557591472,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.8169008071068965,\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 7: {'model_name': 'MobileNetV2',\n",
              "  'A': -0.19212758639777694,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.5609681034005558,\n",
              "  'solution': {'lr': 0.008842528185337765, 'model_index': 1}},\n",
              " 8: {'model_name': 'InceptionV3',\n",
              "  'A': -0.9442201606691986,\n",
              "  'C': 0.0004135063209624752,\n",
              "  'Score': -0.23574491042657778,\n",
              "  'solution': {'lr': 0.009687260779252884, 'model_index': 3}},\n",
              " 9: {'model_name': 'EfficientNetB0',\n",
              "  'A': -0.03140611376185065,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.552214664726647,\n",
              "  'solution': {'lr': 0.01, 'model_index': 0}},\n",
              " 10: {'model_name': 'MobileNetV2',\n",
              "  'A': 1.3063705744192033,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.9355926436048008,\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 11: {'model_name': 'MobileNetV2',\n",
              "  'A': 1.1434057982638959,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.894851449565974,\n",
              "  'solution': {'lr': 0.004468780719721807, 'model_index': 1}},\n",
              " 12: {'model_name': 'MobileNetV2',\n",
              "  'A': 1.0,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.859,\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 13: {'model_name': 'InceptionV3',\n",
              "  'A': 0.2852818560978563,\n",
              "  'C': 0.0004135063209624752,\n",
              "  'Score': 0.07163059376518592,\n",
              "  'solution': {'lr': 0.005174912960528561, 'model_index': 3}},\n",
              " 14: {'model_name': 'InceptionV3',\n",
              "  'A': 0.6922535607954682,\n",
              "  'C': 0.0004135063209624752,\n",
              "  'Score': 0.1733735199395889,\n",
              "  'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oace_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enq1ouE-yILX"
      },
      "source": [
        "Salvando métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIdTSuWEyJ0b"
      },
      "outputs": [],
      "source": [
        "# Salvando as métricas\n",
        "with open('ML_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f)\n",
        "with open('OACE_metrics.json', 'w') as f:\n",
        "    json.dump(oace_metrics, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
