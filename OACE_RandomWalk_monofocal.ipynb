{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8sySYFxXdlI"
      },
      "source": [
        "Importando Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk_zvCtgXYfI",
        "outputId": "a51d884c-2a55-48a0-bbb8-424a48569f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchtext in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (0.18.0)\n",
            "Requirement already satisfied: torchdata in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (0.11.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchtext) (4.66.4)\n",
            "Requirement already satisfied: requests in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from torchdata) (2.2.1)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests->torchtext) (2024.6.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->torchtext) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyDecision in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (4.5.8)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (3.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.26.4)\n",
            "Requirement already satisfied: llmx in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (0.0.21a0)\n",
            "Requirement already satisfied: openai in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.35.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.5.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyDecision) (1.14.0)\n",
            "Requirement already satisfied: pydantic in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (2.7.4)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (0.7.0)\n",
            "Requirement already satisfied: diskcache in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (5.6.3)\n",
            "Requirement already satisfied: cohere in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (5.5.8)\n",
            "Requirement already satisfied: google.auth in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (2.30.0)\n",
            "Requirement already satisfied: typer in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (0.12.3)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from llmx->pyDecision) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyDecision) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (0.27.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from openai->pyDecision) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pyDecision) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pyDecision) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->pyDecision) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->pyDecision) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai->pyDecision) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai->pyDecision) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai->pyDecision) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->pyDecision) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->llmx->pyDecision) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->llmx->pyDecision) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->pyDecision) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai->pyDecision) (0.4.6)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (1.34.133)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (1.9.4)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (0.9.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from cohere->llmx->pyDecision) (2.32.0.20240622)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from google.auth->llmx->pyDecision) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from google.auth->llmx->pyDecision) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from google.auth->llmx->pyDecision) (4.9)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tiktoken->llmx->pyDecision) (2024.5.15)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from typer->llmx->pyDecision) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from typer->llmx->pyDecision) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from typer->llmx->pyDecision) (13.7.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.133 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from boto3<2.0.0,>=1.34.0->cohere->llmx->pyDecision) (1.34.133)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from boto3<2.0.0,>=1.34.0->cohere->llmx->pyDecision) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from boto3<2.0.0,>=1.34.0->cohere->llmx->pyDecision) (0.10.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from pyasn1-modules>=0.2.1->google.auth->llmx->pyDecision) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere->llmx->pyDecision) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->cohere->llmx->pyDecision) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer->llmx->pyDecision) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer->llmx->pyDecision) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers<1,>=0.15->cohere->llmx->pyDecision) (0.23.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere->llmx->pyDecision) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere->llmx->pyDecision) (2024.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lyanh\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->llmx->pyDecision) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install pyDecision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GAEO2YhZXbMr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision.models.inception import InceptionOutputs\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from pyDecision.algorithm import ahp_method\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh3htiCcXfmT"
      },
      "source": [
        "Carregando DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Js9BBmIsMJOA"
      },
      "outputs": [],
      "source": [
        "zip_dataset_warm = '/content/dataset-resized'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPbti20RYEFU",
        "outputId": "a1f9b7af-5b25-4133-e752-e2461c3dbe9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCN3ILrWYGZM"
      },
      "outputs": [],
      "source": [
        "def cifar_10(n_valid=0.2, batch_size=64, num_workers=4):\n",
        "    \"\"\"10 Classes\"\"\"\n",
        "    \n",
        "    transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Resize((224, 224)),\n",
        "                                    transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])])\n",
        "    \n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])  \n",
        "    ])\n",
        "    \n",
        "    train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "    test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "    n_train = len(train_data)\n",
        "    indices = list(range(n_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(n_valid * n_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # Define samplers for obtaining training and validation\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    # Prepare data loaders (combine dataset and sampler)\n",
        "    trainLoader = torch.utils.data.DataLoader(train_data,\n",
        "                                            batch_size = batch_size,\n",
        "                                            sampler = train_sampler,\n",
        "                                            num_workers = num_workers)\n",
        "\n",
        "    validLoader = torch.utils.data.DataLoader(train_data,\n",
        "                                            batch_size = batch_size,\n",
        "                                            sampler = valid_sampler,\n",
        "                                            num_workers = num_workers)\n",
        "\n",
        "    testLoader = torch.utils.data.DataLoader(test_data,\n",
        "                                            batch_size = batch_size,\n",
        "                                            num_workers = num_workers)\n",
        "\n",
        "    classes = train_data.classes\n",
        "    return trainLoader, validLoader, testLoader, classes\n",
        "\n",
        "##### AJUSTA PARA CIFAR-10 SUBSAMPLE #####################\n",
        "\n",
        "def cifar_10_subsample(batch_size=64, num_workers=4, class_labels=['cat', 'dog']):\n",
        "    \"\"\"CIFAR-10 with only two selected classes for warm\"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Resize((224, 224)),\n",
        "                                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "    \n",
        "    # Load the entire CIFAR-10 test dataset\n",
        "    test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "    # Filter out only the specified classes\n",
        "    test_indices = [i for i, label in enumerate(test_data.targets) if test_data.classes[label] in class_labels]\n",
        "\n",
        "    # Map the selected classes to new labels (0 and 1)\n",
        "    test_data.targets = [test_data.targets[i] for i in test_indices]\n",
        "    test_data.data = test_data.data[test_indices]\n",
        "\n",
        "    label_map = {test_data.classes.index(class_labels[0]): 0,\n",
        "                 test_data.classes.index(class_labels[1]): 1}\n",
        "\n",
        "    test_data.targets = [label_map[label] for label in test_data.targets]\n",
        "\n",
        "    # Prepare data loader for test data\n",
        "    testLoader = DataLoader(test_data, \n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers)\n",
        "    \n",
        "    classes = class_labels\n",
        "    \n",
        "    return testLoader, classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcdgrjRmYi0Z"
      },
      "source": [
        "#### Definindo os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFd_xpT4YlkD"
      },
      "outputs": [],
      "source": [
        "def get_efficientnet_b0(num_classes=10):\n",
        "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "    if hasattr(model.classifier, 'in_features'):\n",
        "        in_features = model.classifier.in_features\n",
        "    elif hasattr(model.classifier, 'fc'):\n",
        "        in_features = model.classifier.fc.in_features\n",
        "    else:\n",
        "        in_features = model.classifier[-1].in_features\n",
        "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_mobilenet_v2(num_classes=10):\n",
        "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_resnet50(num_classes=10):\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_inception_v3(num_classes=10):\n",
        "    model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, aux_logits=True)\n",
        "    model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "def get_vgg16(num_classes=10):\n",
        "    #model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
        "    #model = models.vgg13(weights=models.VGG13_Weights.IMAGENET1K_V1)\n",
        "    #model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "    model = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "    # Congelar as camadas convolucionais\n",
        "    #for param in model.features.parameters():\n",
        "    #    param.requires_grad = False\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    return model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-CfdRq2ZvoZ"
      },
      "source": [
        "#### Defini√ß√£o das fun√ß√µes do M√©todo OACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XdxC0KSfZyu-"
      },
      "outputs": [],
      "source": [
        "metrics_a = [\"precision\", \"accuracy\", \"recall\"]\n",
        "metrics_c = [\"mtp\", \"tpi\", \"ms\"]\n",
        "epsilon = 1e-5 # Par√¢metro da padroniza√ß√£o para evitar divis√£o por zero\n",
        "### AHP Method ###\n",
        "weight_derivation = 'geometric' # 'mean'; 'geometric' or 'max_eigen'\n",
        "dataset = np.array([# Dataset for assertiveness metrics (P -> A -> R)\n",
        "  #P      A      R\n",
        "  [1  ,   5,     7   ],   #P\n",
        "  [1/5,   1,     3   ],   #A\n",
        "  [1/7,   1/3,   1   ],   #R\n",
        "])\n",
        "dataset = np.array([ # Dataset for cost metrics (MTP -> TPI -> MS)\n",
        "  #MTP    TPI    MS\n",
        "  [  1,     5,   7   ],   #MTP\n",
        "  [1/5,     1,   3   ],   #TPI\n",
        "  [1/7,   1/3,   1   ],   #MS\n",
        "])\n",
        "\n",
        "weights, rc = ahp_method(dataset, wd = weight_derivation)\n",
        "w1, w2, w3 = weights[0], weights[1], weights[2]\n",
        "wa = [w1, w2, w3] # Precision, Acuraccy, Recall\n",
        "wc = [w1, w2, w3] # MTP, TPI, MS\n",
        "\n",
        "def get_max_min_metrics(metrics_dict):\n",
        "    \"\"\"Calcula os m√°ximos e m√≠nimos das m√©tricas de custo resultante do aquecimento dos modelos\"\"\"\n",
        "    metricas_custo = ['mtp', 'tpi', 'ms']\n",
        "\n",
        "    max_custo = {metrica: float('-inf') for metrica in metricas_custo}\n",
        "    min_custo = {metrica: float('inf') for metrica in metricas_custo}\n",
        "\n",
        "    for model_name, metrics in metrics_dict.items():\n",
        "        for metrica in metricas_custo:\n",
        "            valor = metrics[metrica]\n",
        "            if valor > max_custo[metrica]:\n",
        "                max_custo[metrica] = valor\n",
        "            if valor < min_custo[metrica]:\n",
        "                min_custo[metrica] = valor\n",
        "\n",
        "    # Convertendo os dicion√°rios de m√°ximos e m√≠nimos em listas simples\n",
        "    max_custo_list = [max_custo[metrica] for metrica in metricas_custo]\n",
        "    min_custo_list = [min_custo[metrica] for metrica in metricas_custo]\n",
        "\n",
        "    return max_custo_list, min_custo_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def N(value, max_value, min_value):\n",
        "    \"\"\"Fun√ß√£o de normaliza√ß√£o min-max, com clamp para garantir valores entre 0 e 1 e logs para valores fora do intervalo.\"\"\"\n",
        "    if max_value is None or min_value is None or max_value == min_value:\n",
        "        return 0.0\n",
        "    normalized = (value - min_value) / (max_value - min_value)\n",
        "    return max(0.0, min(1.0, normalized))  # Clampa entre 0 e 1\n",
        "\n",
        "def N_cost(value, max_value, min_value):\n",
        "    if max_value is None or min_value is None or max_value == min_value:\n",
        "        return 0.0\n",
        "    normalized = (max_value - value) / (max_value - min_value)\n",
        "    return max(0.0, min(1.0, normalized))  \n",
        "\n",
        "def A(metrics, wa, metricas_a, maximos_a, minimos_a):\n",
        "    \"\"\"Calcula a assertividade normalizada.\"\"\"\n",
        "    a_i = [metrics['assertividade'][metrica] for metrica in metricas_a]\n",
        "    normalized_values = [N(a, maximo, minimo) for a, maximo, minimo in zip(a_i, maximos_a, minimos_a)]\n",
        "    return sum([n * w for n, w in zip(normalized_values, wa)])\n",
        "\n",
        "def C(metrics, wc, metricas_c, maximos_c, minimos_c):\n",
        "    \"\"\"Calcula o custo normalizado.\"\"\"\n",
        "    c_i = [metrics['custo'][metrica] for metrica in metricas_c]\n",
        "    normalized_values = [N_cost(c, maximo, minimo) for c, maximo, minimo in zip(c_i, maximos_c, minimos_c)]\n",
        "    return sum([n * w for n, w in zip(normalized_values, wc)])\n",
        "\n",
        "def F_score(lambda_, assertiveness, cost, max_score, min_score):\n",
        "    \"\"\"Calcula o score do m√©todo e normaliza.\"\"\"\n",
        "    score = lambda_ * assertiveness + (1 - lambda_) * cost\n",
        "    return N(score, max_score, min_score)\n",
        "\n",
        "def calculo_maximos_minimos(accumulated_metrics, metricas, tipo):\n",
        "    \"\"\"Calcula os m√°ximos e m√≠nimos para normaliza√ß√£o das m√©tricas.\"\"\"\n",
        "    if not accumulated_metrics:\n",
        "        return [0.0] * len(metricas), [0.0] * len(metricas)  # Valores padr√£o para evitar erros iniciais\n",
        "\n",
        "    valores = {metrica: [] for metrica in metricas}\n",
        "    for metrics in accumulated_metrics:\n",
        "        for metrica in metricas:\n",
        "            valores[metrica].append(float(metrics[tipo][metrica]))\n",
        "\n",
        "    maximos = [np.max(valores[metrica]) for metrica in metricas]\n",
        "    minimos = [np.min(valores[metrica]) for metrica in metricas]\n",
        "    return maximos, minimos\n",
        "\n",
        "def calcular_metricas_oace(iteration_metrics, accumulated_metrics, lambda_, wa, wc, metricas_a, metricas_c, maximos_a=None, minimos_a=None, maximos_c=None, minimos_c=None):\n",
        "    print(\"\\nüîé INICIANDO A AVALIA√á√ÉO DO OACE PARA ITERA√á√ÉO ATUAL\")\n",
        "    print(\"iteration_metrics: \", iteration_metrics)\n",
        "    print(\"accumulated_metrics: \", accumulated_metrics)\n",
        "\n",
        "    if not iteration_metrics:\n",
        "        return None\n",
        "    if maximos_a is None or minimos_a is None:\n",
        "        maximos_a, minimos_a = calculo_maximos_minimos(accumulated_metrics, metricas_a, \"assertividade\")\n",
        "        \n",
        "    print(\"maximos_a: \", maximos_a)\n",
        "    print(\"minimos_a: \", minimos_a)\n",
        "    print(\"maximos_c (fixos do aquecimento): \", maximos_c)\n",
        "    print(\"minimos_c (fixos do aquecimento): \", minimos_c)\n",
        "\n",
        "    max_score = lambda_ * 1.0 + (1 - lambda_) * 1.0  # M√°ximo te√≥rico\n",
        "    min_score = lambda_ * 0.0 + (1 - lambda_) * 0.0  # M√≠nimo te√≥rico\n",
        "\n",
        "    assertividade = A(iteration_metrics, wa, metricas_a, maximos_a, minimos_a)\n",
        "    print(\"üîπ A (Assertividade Normalizada): \", assertividade)\n",
        "    custo = C(iteration_metrics, wc, metricas_c, maximos_c, minimos_c)\n",
        "    print(\"üîπ C (Custo Normalizado): \", custo)\n",
        "    score = F_score(lambda_, assertividade, custo, max_score, min_score)\n",
        "    print(\"üîπ S (Score OACE): \", score)\n",
        "\n",
        "    return {\n",
        "        \"model_name\": iteration_metrics[\"model_name\"],\n",
        "        \"A\": assertividade,\n",
        "        \"C\": custo,\n",
        "        \"Score\": score,\n",
        "        \"solution\": iteration_metrics[\"solution\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giVOsdD_aUZs"
      },
      "source": [
        "#### C√≥digo para hyperparametriza√ß√£o do m√©todo com random walk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmZ-joEyaWxG"
      },
      "source": [
        "Gerando as solu√ß√µes com o random walk (alterar para configurar a semente random.seed())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hUTvmNeDaXn6"
      },
      "outputs": [],
      "source": [
        "def generate_solution(model_list):\n",
        "    \"\"\"Gera uma solu√ß√£o inicial para o Random Walk, em termos de taxa de aprendizado (lr) e modelo\"\"\"\n",
        "    lr = random.uniform(1e-4, 1e-2)\n",
        "    model_index = random.randint(0, len(model_list) - 1)  # Escolhe um modelo da lista\n",
        "    return [lr, model_index]\n",
        "\n",
        "def random_walk_step(solution, model_list, step_size=0.1):\n",
        "    \"\"\"Executa um passo do Random Walk para explorar novas solu√ß√µes\"\"\"\n",
        "    new_solution = solution.copy()\n",
        "    new_solution[0] = min(max(new_solution[0] + random.uniform(-step_size * new_solution[0], step_size * new_solution[0]), 1e-4), 1e-2)\n",
        "    new_solution[1] = random.randint(0, len(model_list) - 1)  # Seleciona outro modelo aleatoriamente\n",
        "    return new_solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMWtdA00wpgu"
      },
      "source": [
        "Fun√ß√µes para treinamento e valida√ß√£o dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "H2tgn4eQwnWk"
      },
      "outputs": [],
      "source": [
        "def train_models(model, trainLoader, validLoader, criterion, optimizer, epochs=30, early_stopping_rounds=5):\n",
        "    \"\"\"Treina o modelo e monitora a perda de valida√ß√£o para aplicar early stopping.\"\"\"\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_count = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        model.train()\n",
        "        for data, target in trainLoader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Redimensionamento din√¢mico se necess√°rio\n",
        "            if isinstance(model, models.Inception3):\n",
        "                data = F.interpolate(data, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "\n",
        "            # Verifica se a sa√≠da √© do tipo InceptionOutputs\n",
        "            if isinstance(output, InceptionOutputs):\n",
        "                output = output.logits  # Usa apenas a sa√≠da principal\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in validLoader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                 # Redimensionamento din√¢mico se necess√°rio\n",
        "                if isinstance(model, models.Inception3):\n",
        "                    data = F.interpolate(data, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "                output = model(data)\n",
        "                # Verifica se a sa√≠da √© do tipo InceptionOutputs\n",
        "                if isinstance(output, InceptionOutputs):\n",
        "                    output = output.logits  # Usa apenas a sa√≠da principal\n",
        "                loss = criterion(output, target)\n",
        "                valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(trainLoader.dataset)\n",
        "        valid_loss = valid_loss/len(validLoader.dataset)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "\n",
        "        if valid_loss < best_val_loss:\n",
        "            best_val_loss = valid_loss\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "\n",
        "        if no_improvement_count >= early_stopping_rounds:\n",
        "            print(f\"Early stopping after {epoch} epochs due to no improvement.\")\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_solution(model, trainLoader, testLoader, validLoader, criterion, optimizer, dataset_name):\n",
        "    \"\"\"\n",
        "    - Avalia uma solu√ß√£o de modelo treinado medindo sua precis√£o, acur√°cia, recall, tempo de infer√™ncia, tamanho e n√∫mero de par√¢metros.\n",
        "    - Esta fun√ß√£o treina o modelo, realiza infer√™ncias no conjunto de testes e calcula v√°rias m√©tricas de desempenho, incluindo assertividade e custo computacional.\n",
        "    \"\"\"\n",
        "    model = train_models(model, trainLoader, validLoader, criterion, optimizer)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, target in testLoader:\n",
        "            inputs, target = inputs.to(device), target.to(device)\n",
        "\n",
        "            # Redimensionamento din√¢mico se necess√°rio\n",
        "            if isinstance(model, models.Inception3):\n",
        "                inputs = F.interpolate(inputs, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            inference_time = time.time() - start_time\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(target.cpu().numpy())\n",
        "            inference_times.append(inference_time)\n",
        "\n",
        "    # Defina o valor de 'average' com base no tipo de dataset\n",
        "    if dataset_name == \"Chest X-Ray\":\n",
        "        average_type = 'binary'\n",
        "    else:\n",
        "        average_type = 'macro'\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, average=average_type, zero_division=0)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds, average=average_type, zero_division=0)# No dataset char x-ray average binary deve ser utilizada, para o restanto, micro ou average\n",
        "\n",
        "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
        "    num_params = sum(p.numel() for p in model.parameters()) \n",
        "    model_size = sum(p.element_size() * p.numel() for p in model.parameters()) / (1024 ** 2)\n",
        "\n",
        "    return float(precision), accuracy, float(recall), avg_inference_time, model_size, num_params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fun√ß√£o para Aquecimento dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warm_calculate_metrics(model, dataloader, device):\n",
        "    \"\"\"Calcula as m√©tricas de custo no aquecimento para um modelo dado\"\"\"\n",
        "    model.eval()\n",
        "    total_inference_time = 0.0\n",
        "\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, target in dataloader:\n",
        "            inputs, target = inputs.to(device), target.to(device)\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            inference_time = time.time() - start_time\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            inference_times.append(inference_time)\n",
        "\n",
        "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    model_size = sum(p.element_size() * p.numel() for p in model.parameters()) / (1024**2)  # Size in MB\n",
        "\n",
        "    return num_params, avg_inference_time, model_size\n",
        "\n",
        "def warm_up_models(models, dataloader, device):\n",
        "    metrics = {}\n",
        "    for model_name, get_model_func in models:\n",
        "        model = get_model_func().to(device)\n",
        "        num_params, avg_inference_time, model_size = warm_calculate_metrics(model, dataloader, device)\n",
        "        metrics[model_name] = {\n",
        "            'mtp': num_params,\n",
        "            'tpi': avg_inference_time,\n",
        "            'ms': model_size\n",
        "        }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(current_round, iteration, best_model_overall, best_score_overall, best_solution_overall,\n",
        "                    metrics_per_iteration, oace_metrics_per_iteration, max_assertiveness_max, max_assertiveness_min, checkpoint_path):\n",
        "    \"\"\"Salva o estado atual do treinamento para continuar depois.\"\"\"\n",
        "    checkpoint_data = {\n",
        "        'current_round': current_round,\n",
        "        'iteration': iteration,\n",
        "        'best_model_overall': best_model_overall,\n",
        "        'best_score_overall': best_score_overall,\n",
        "        'best_solution_overall': best_solution_overall,\n",
        "        'metrics_per_iteration': metrics_per_iteration,  # Armazena todas as itera√ß√µes\n",
        "        'oace_metrics_per_iteration': oace_metrics_per_iteration,  # Armazena todas as m√©tricas OACE\n",
        "        'max_assertiveness_max': max_assertiveness_max,\n",
        "        'max_assertiveness_min': max_assertiveness_min\n",
        "    }\n",
        "    with open(checkpoint_path, 'wb') as f:\n",
        "        pickle.dump(checkpoint_data, f)\n",
        "    print(f\"‚úÖ Checkpoint salvo na Rodada {current_round + 1}, Itera√ß√£o {iteration + 1}.\")\n",
        "\n",
        "def load_checkpoint(checkpoint_path):\n",
        "    \"\"\"Carrega o checkpoint, se existir.\"\"\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        with open(checkpoint_path, 'rb') as f:\n",
        "            checkpoint = pickle.load(f)\n",
        "        return checkpoint\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwAUnOIma9uK"
      },
      "source": [
        "Fun√ß√£o principal para execu√ß√£o do m√©todo (alterar para ajustar para nova metodologia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_hyperparameters(models_list, trainloader, testloader, validLoader, classes, lbd, wa, wc, dataset_name, checkpoint_path, num_rounds=3, iterations_per_round=10, save_checkpoint_every=5):\n",
        "    \n",
        "    initial_seeds = [100, 600, 1100]  # Seeds fixas, pode ser [50, 150, 200], [100, 600, 1100] ou [1000, 2500, 4000]\n",
        "\n",
        "    checkpoint = load_checkpoint(checkpoint_path)\n",
        "    if checkpoint:\n",
        "        current_round = checkpoint['current_round']\n",
        "        iteration = checkpoint['iteration']\n",
        "        best_model_overall = checkpoint['best_model_overall']\n",
        "        best_score_overall = checkpoint['best_score_overall']\n",
        "        best_solution_overall = checkpoint['best_solution_overall']\n",
        "        metrics_per_iteration = checkpoint['metrics_per_iteration']  \n",
        "        oace_metrics_per_iteration = checkpoint['oace_metrics_per_iteration']  \n",
        "        maximos_a = checkpoint['max_assertiveness_max']  \n",
        "        minimos_a = checkpoint['max_assertiveness_min']  \n",
        "\n",
        "        print(f\"üîÑ Continua√ß√£o do treinamento a partir da Rodada {current_round + 1}, Itera√ß√£o {iteration + 1}...\")\n",
        "    else:\n",
        "        current_round = 0\n",
        "        iteration = 0  \n",
        "        best_model_overall = None\n",
        "        best_score_overall = float('-inf')\n",
        "        best_solution_overall = None\n",
        "        metrics_per_iteration = {}  # Dicion√°rio para todas as itera√ß√µes\n",
        "        oace_metrics_per_iteration = {}  # Dicion√°rio para todas as m√©tricas OACE\n",
        "        maximos_a, minimos_a = None, None  # Inicia como None para recalcular ou carregar do checkpoint\n",
        "\n",
        "    with open('warm_up_metrics.pkl', 'rb') as f:\n",
        "        warm_up_metrics = pickle.load(f)\n",
        "\n",
        "    maximos_c, minimos_c = get_max_min_metrics(warm_up_metrics)\n",
        "\n",
        "    accumulated_metrics = []  # Para calcular m√°ximos/m√≠nimos de assertividade\n",
        "    total_iterations = num_rounds * iterations_per_round  # Total de itera√ß√µes globais\n",
        "\n",
        "    for round_idx in range(current_round, num_rounds):\n",
        "        print(f\"\\nüîÑ Iniciando Rodada {round_idx + 1}/{num_rounds} üîÑ\")\n",
        "        base_seed = initial_seeds[round_idx] \n",
        "        best_model = None\n",
        "        best_score = float('-inf')\n",
        "        best_solution = None if not checkpoint or round_idx > current_round else best_solution_overall\n",
        "\n",
        "        # Reinicia a solu√ß√£o se for um novo round ap√≥s o checkpoint\n",
        "        if round_idx > current_round or not checkpoint:\n",
        "            solution = generate_solution(models_list)\n",
        "        else:\n",
        "            solution = best_solution_overall\n",
        "\n",
        "        # Itera sobre as itera√ß√µes desta rodada, incrementando a seed\n",
        "        for local_iteration in range(iterations_per_round):\n",
        "            global_iteration = round_idx * iterations_per_round + local_iteration  # Itera√ß√£o global\n",
        "            if global_iteration <= iteration and checkpoint:  # Pula itera√ß√µes j√° processadas\n",
        "                continue\n",
        "\n",
        "            current_seed = base_seed + local_iteration  # Incrementa a seed dentro do round\n",
        "            random.seed(current_seed)\n",
        "\n",
        "            print(f\"‚ñ∂Ô∏è Iteration {global_iteration + 1}/{total_iterations} (Round {round_idx + 1}): model {solution[1]} e lr {solution[0]}\")\n",
        "            print(f\"üîÄ Random Seed Atual: {current_seed}\")\n",
        "\n",
        "            model_name, Model = models_list[solution[1]]\n",
        "            model = Model(num_classes=len(classes)).to(device)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=solution[0])\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            precision, accuracy, recall, avg_inference_time, model_size, num_params = evaluate_solution(\n",
        "                model, trainloader, testloader, validLoader, criterion, optimizer, dataset_name)\n",
        "\n",
        "            current_metrics = {\n",
        "                \"model_name\": model_name,\n",
        "                \"assertividade\": {\"precision\": precision, \"accuracy\": accuracy, \"recall\": recall},\n",
        "                \"custo\": {\"mtp\": num_params, \"tpi\": avg_inference_time, \"ms\": model_size},\n",
        "                \"solution\": {\"lr\": solution[0], \"model_index\": solution[1]}\n",
        "            }\n",
        "\n",
        "            accumulated_metrics.append(current_metrics)\n",
        "            metrics_per_iteration[global_iteration] = current_metrics\n",
        "\n",
        "            # Calcular OACE usando os custos fixos do aquecimento e os m√°ximos/m√≠nimos de assertividade carregados ou atualizados\n",
        "            oace_metrics = calcular_metricas_oace(\n",
        "                current_metrics,\n",
        "                accumulated_metrics,\n",
        "                lbd, wa, wc,\n",
        "                [\"precision\", \"accuracy\", \"recall\"],\n",
        "                [\"mtp\", \"tpi\", \"ms\"],\n",
        "                maximos_a, minimos_a,\n",
        "                maximos_c, minimos_c\n",
        "            )\n",
        "            oace_metrics_per_iteration[global_iteration] = oace_metrics\n",
        "\n",
        "            print(\"Resultado do OACE por Itera√ß√£o: \", oace_metrics)\n",
        "            score = oace_metrics[\"Score\"]\n",
        "\n",
        "            # Atualizar o melhor modelo globalmente (sobre todas as itera√ß√µes)\n",
        "            if score > best_score_overall:\n",
        "                best_score_overall = score\n",
        "                best_model_overall = model_name\n",
        "                best_solution_overall = solution.copy()\n",
        "\n",
        "            solution = random_walk_step(solution, models_list)\n",
        "\n",
        "            # Salvar checkpoint a cada 'save_checkpoint_every' itera√ß√µes globais\n",
        "            if (global_iteration + 1) % save_checkpoint_every == 0 or global_iteration == total_iterations - 1:\n",
        "                save_checkpoint(\n",
        "                    round_idx, global_iteration, best_model_overall, best_score_overall, best_solution_overall,\n",
        "                    metrics_per_iteration, oace_metrics_per_iteration, maximos_a, minimos_a, checkpoint_path\n",
        "                )\n",
        "\n",
        "        # Atualizar m√°ximos e m√≠nimos de assertividade ao final de cada round\n",
        "        current_max_a, current_min_a = calculo_maximos_minimos(accumulated_metrics, [\"precision\", \"accuracy\", \"recall\"], \"assertividade\")\n",
        "        if maximos_a is None or minimos_a is None:\n",
        "            maximos_a, minimos_a = current_max_a, current_min_a\n",
        "        else:\n",
        "            for i in range(len(current_max_a)):\n",
        "                maximos_a[i] = max(maximos_a[i], current_max_a[i])\n",
        "                minimos_a[i] = min(minimos_a[i], current_min_a[i])\n",
        "\n",
        "    return best_model_overall, best_score_overall, best_solution_overall, metrics_per_iteration, oace_metrics_per_iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxXHsRrxcqp"
      },
      "source": [
        "C√≥digo principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iFGsEK4_O0Gp"
      },
      "outputs": [],
      "source": [
        "datasets_options = {\n",
        "        '1': 'Chest X-Ray',\n",
        "        '2': 'CIFAR-10',\n",
        "        '3': 'TrashNet'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHXpibmGxjD_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#train_dir = '/content/drive/MyDrive/MeÃÅtodo OACE/datasets/chest_xray/train'\n",
        "#val_dir = '/content/drive/MyDrive/MeÃÅtodo OACE/datasets/chest_xray/val'\n",
        "#test_dir = '/content/drive/MyDrive/MeÃÅtodo OACE/datasets/chest_xray/test'\n",
        "#lbd = 0.75\n",
        "#trainLoader, validLoader, testLoader, classes = chest_x_ray(train_dir, val_dir, test_dir)\n",
        "\n",
        "#subsample_loader, subsample_classes = chest_x_ray_subsample(test_dir)\n",
        "################################################################################\n",
        "# CIFAR-10\n",
        "lbd = 0.5\n",
        "trainLoader, validLoader, testLoader, classes = cifar_10(batch_size=64)\n",
        "dataset_name = datasets_options['2']\n",
        "#subsample_loader, subsample_classes = cifar_10_subsample()\n",
        "################################################################################\n",
        "# TrashNet\n",
        "#lbd = 0.25\n",
        "#dataset_dir = 'datasets/dataset-resized'\n",
        "#trainLoader, validLoader, testLoader, classes = trashNet(dataset_dir)\n",
        "#ataset_name = datasets_options['3']\n",
        "#subsample_loader, subsample_classes = trashNet_subsample(dataset_dir)\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "625"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEAY3DdkXlv3",
        "outputId": "d6b1b908-3905-4390-8933-e670b80d7823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch de imagens shape: torch.Size([64, 3, 32, 32])\n",
            "Batch de r√≥tulos shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in trainLoader:\n",
        "    print(f\"Batch de imagens shape: {images.shape}\")\n",
        "    print(f\"Batch de r√≥tulos shape: {labels.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "gcVeh31uxn-9",
        "outputId": "b22e60c5-d131-4378-e894-0cb62e49435c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFORMA√á√ïES SOBRE O AMBIENTE DE EXECU√á√ÉO:\n",
            "PyTorch version: 2.3.1+cu121\n",
            "CUDA available: True\n",
            "CUDA version: 12.1\n",
            "Number of GPUs: 1\n",
            "Current GPU: 0\n",
            "GPU name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
            "\n",
            "Iniciando o aquecimento dos modelos...\n",
            "\n",
            "Classes dos dados para aquecimento: ['glass', 'plastic']\n",
            "Batch de imagens shape: torch.Size([16, 3, 224, 224])\n",
            "Batch de r√≥tulos shape: torch.Size([16])\n",
            "Warm-up conclu√≠do e m√©tricas salvas.\n"
          ]
        }
      ],
      "source": [
        "models_list = [\n",
        "    (\"EfficientNetB0\", get_efficientnet_b0),\n",
        "    (\"MobileNetV2\", get_mobilenet_v2),\n",
        "    (\"ResNet50\", get_resnet50),\n",
        "    (\"InceptionV3\", get_inception_v3),\n",
        "    (\"VGG16\", get_vgg16)\n",
        "]\n",
        "\n",
        "wa = [0.731, 0.188, 0.081]  # Pesos para Precision, Accuracy, Recall\n",
        "wc = [0.731, 0.188, 0.081]  # Pesos para MTP, TPI, MS\n",
        "\n",
        "print(\"INFORMA√á√ïES SOBRE O AMBIENTE DE EXECU√á√ÉO:\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
        "\n",
        "print(\"\\nIniciando o aquecimento dos modelos...\\n\")\n",
        "subsample_loader, subsample_classes = cifar_10_subsample()  # Atualize para o caminho correto\n",
        "print(\"Classes dos dados para aquecimento:\", subsample_classes)\n",
        "for images, labels in subsample_loader:\n",
        "    print(f\"Batch de imagens shape: {images.shape}\")\n",
        "    print(f\"Batch de r√≥tulos shape: {labels.shape}\")\n",
        "    break\n",
        "warm_up_metrics = warm_up_models(models_list, subsample_loader, device)\n",
        "with open('warm_up_metrics.pkl', 'wb') as f:\n",
        "    pickle.dump(warm_up_metrics, f)\n",
        "    \n",
        "print(\"Warm-up conclu√≠do e m√©tricas salvas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Iniciando Rodada 1/3 üîÑ\n",
            "‚ñ∂Ô∏è Iteration 1/15 (Round 1): model 1 e lr 0.0015668949432321277\n",
            "üîÄ Random Seed Atual: 100\n",
            "Epoch: 1 \tTraining Loss: 1.433616 \tValidation Loss: 0.326847\n",
            "Epoch: 2 \tTraining Loss: 1.197285 \tValidation Loss: 0.263113\n",
            "Epoch: 3 \tTraining Loss: 0.983905 \tValidation Loss: 0.431060\n",
            "Epoch: 4 \tTraining Loss: 0.962569 \tValidation Loss: 0.336314\n",
            "Epoch: 5 \tTraining Loss: 0.900942 \tValidation Loss: 0.252637\n",
            "Epoch: 6 \tTraining Loss: 0.789127 \tValidation Loss: 0.228569\n",
            "Epoch: 7 \tTraining Loss: 0.718747 \tValidation Loss: 0.149641\n",
            "Epoch: 8 \tTraining Loss: 0.696015 \tValidation Loss: 0.144554\n",
            "Epoch: 9 \tTraining Loss: 0.771429 \tValidation Loss: 0.179300\n",
            "Epoch: 10 \tTraining Loss: 1.031334 \tValidation Loss: 0.270777\n",
            "Epoch: 11 \tTraining Loss: 0.859582 \tValidation Loss: 0.224003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000019E93FCA660>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Lyanh\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"C:\\Users\\Lyanh\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1437, in _shutdown_workers\n",
            "    if self._persistent_workers or self._workers_status[worker_id]:\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12 \tTraining Loss: 0.699431 \tValidation Loss: 0.139094\n",
            "Epoch: 13 \tTraining Loss: 0.647175 \tValidation Loss: 0.145645\n",
            "Epoch: 14 \tTraining Loss: 0.591448 \tValidation Loss: 0.299325\n",
            "Epoch: 15 \tTraining Loss: 1.250400 \tValidation Loss: 0.251481\n",
            "Epoch: 16 \tTraining Loss: 0.859407 \tValidation Loss: 0.199170\n",
            "Epoch: 17 \tTraining Loss: 0.695167 \tValidation Loss: 0.159630\n",
            "Early stopping after 17 epochs due to no improvement.\n",
            "\n",
            "üîé INICIANDO A AVALIA√á√ÉO DO OACE PARA ITERA√á√ÉO ATUAL\n",
            "iteration_metrics:  {'model_name': 'VGG16', 'assertividade': {'precision': 0.7618229307836331, 'accuracy': 0.7569, 'recall': 0.7569000000000001}, 'custo': {'mtp': 134309962, 'tpi': 0.06843847226185404, 'ms': 512.3518447875977}, 'solution': {'lr': 0.0015668949432321277, 'model_index': 1}}\n",
            "accumulated_metrics:  [{'model_name': 'VGG16', 'assertividade': {'precision': 0.7618229307836331, 'accuracy': 0.7569, 'recall': 0.7569000000000001}, 'custo': {'mtp': 134309962, 'tpi': 0.06843847226185404, 'ms': 512.3518447875977}, 'solution': {'lr': 0.0015668949432321277, 'model_index': 1}}]\n",
            "maximos_a:  [0.7618229307836331, 0.7569, 0.7569000000000001]\n",
            "minimos_a:  [0.7618229307836331, 0.7569, 0.7569000000000001]\n",
            "maximos_c (fixos do aquecimento):  [134309962, 0.02737882060389365, 512.3518447875977]\n",
            "minimos_c (fixos do aquecimento):  [24371444, 0.004024182596514302, 92.96968078613281]\n",
            "üîπ A (Assertividade Normalizada):  0.0\n",
            "üîπ C (Custo Normalizado):  0.0\n",
            "üîπ S (Score OACE):  0.0\n",
            "Resultado do OACE por Itera√ß√£o:  {'model_name': 'VGG16', 'A': 0.0, 'C': 0.0, 'Score': 0.0, 'solution': {'lr': 0.0015668949432321277, 'model_index': 1}}\n",
            "‚ñ∂Ô∏è Iteration 2/15 (Round 1): model 1 e lr 0.0014558551327503255\n",
            "üîÄ Random Seed Atual: 101\n",
            "Epoch: 1 \tTraining Loss: 1.318665 \tValidation Loss: 0.426459\n",
            "Epoch: 2 \tTraining Loss: 1.046726 \tValidation Loss: 0.268672\n",
            "Epoch: 3 \tTraining Loss: 0.886627 \tValidation Loss: 0.185235\n",
            "Epoch: 4 \tTraining Loss: 0.819273 \tValidation Loss: 0.188056\n",
            "Epoch: 5 \tTraining Loss: 0.754383 \tValidation Loss: 0.217344\n",
            "Epoch: 6 \tTraining Loss: 0.758471 \tValidation Loss: 0.176307\n",
            "Epoch: 7 \tTraining Loss: 0.767261 \tValidation Loss: 0.170468\n",
            "Epoch: 8 \tTraining Loss: 0.795551 \tValidation Loss: 0.226081\n",
            "Epoch: 9 \tTraining Loss: 1.160596 \tValidation Loss: 0.235427\n",
            "Epoch: 10 \tTraining Loss: 0.816259 \tValidation Loss: 0.163398\n",
            "Epoch: 11 \tTraining Loss: 0.728811 \tValidation Loss: 0.222913\n",
            "Epoch: 12 \tTraining Loss: 0.658074 \tValidation Loss: 0.172117\n",
            "Epoch: 13 \tTraining Loss: 0.583035 \tValidation Loss: 0.194690\n",
            "Epoch: 14 \tTraining Loss: 0.643328 \tValidation Loss: 0.207362\n",
            "Epoch: 15 \tTraining Loss: 0.645473 \tValidation Loss: 0.158343\n",
            "Epoch: 16 \tTraining Loss: 0.624430 \tValidation Loss: 0.229201\n",
            "Epoch: 17 \tTraining Loss: 0.659495 \tValidation Loss: 0.151667\n",
            "Epoch: 18 \tTraining Loss: 0.827482 \tValidation Loss: 0.265079\n",
            "Epoch: 19 \tTraining Loss: 0.754660 \tValidation Loss: 0.140073\n",
            "Epoch: 20 \tTraining Loss: 0.561261 \tValidation Loss: 0.150237\n",
            "Epoch: 21 \tTraining Loss: 0.487528 \tValidation Loss: 0.221773\n",
            "Epoch: 22 \tTraining Loss: 0.490732 \tValidation Loss: 0.133216\n",
            "Epoch: 23 \tTraining Loss: 0.430663 \tValidation Loss: 0.160467\n",
            "Epoch: 24 \tTraining Loss: 0.448668 \tValidation Loss: 0.114053\n",
            "Epoch: 25 \tTraining Loss: 0.419687 \tValidation Loss: 0.106620\n",
            "Epoch: 26 \tTraining Loss: 0.493801 \tValidation Loss: 0.133046\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m best_model, best_score, best_solution, metrics, oace_metrics \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations_per_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                                                                        \u001b[49m\u001b[43msave_checkpoint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[31], line 66\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(models_list, trainloader, testloader, validLoader, classes, lbd, wa, wc, dataset_name, checkpoint_path, num_rounds, iterations_per_round, save_checkpoint_every)\u001b[0m\n\u001b[0;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39msolution[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     64\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 66\u001b[0m precision, accuracy, recall, avg_inference_time, model_size, num_params \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_solution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m current_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertividade\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall},\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcusto\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmtp\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_params, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtpi\u001b[39m\u001b[38;5;124m\"\u001b[39m: avg_inference_time, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_size},\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: solution[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: solution[\u001b[38;5;241m1\u001b[39m]}\n\u001b[0;32m     74\u001b[0m }\n\u001b[0;32m     76\u001b[0m accumulated_metrics\u001b[38;5;241m.\u001b[39mappend(current_metrics)\n",
            "Cell \u001b[1;32mIn[37], line 71\u001b[0m, in \u001b[0;36mevaluate_solution\u001b[1;34m(model, trainLoader, testLoader, validLoader, criterion, optimizer, dataset_name)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_solution\u001b[39m(model, trainLoader, testLoader, validLoader, criterion, optimizer, dataset_name):\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    - Avalia uma solu√ß√£o de modelo treinado medindo sua precis√£o, acur√°cia, recall, tempo de infer√™ncia, tamanho e n√∫mero de par√¢metros.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    - Esta fun√ß√£o treina o modelo, realiza infer√™ncias no conjunto de testes e calcula v√°rias m√©tricas de desempenho, incluindo assertividade e custo computacional.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     73\u001b[0m     all_preds \u001b[38;5;241m=\u001b[39m []\n",
            "Cell \u001b[1;32mIn[37], line 29\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(model, trainLoader, validLoader, criterion, optimizer, epochs, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 29\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"checkpoint.pkl\"\n",
        "best_model, best_score, best_solution, metrics, oace_metrics = optimize_hyperparameters(models_list, \n",
        "                                                                                        trainLoader, testLoader, validLoader, \n",
        "                                                                                        classes, lbd, wa, wc,\n",
        "                                                                                        dataset_name, checkpoint_path, \n",
        "                                                                                        num_rounds=3, iterations_per_round=5, \n",
        "                                                                                        save_checkpoint_every=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4tlP5z7xyQr",
        "outputId": "ab3c1e58-9cc0-4f24-824f-8a7acd72d48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model: MobileNetV2\n",
            "Best Score: 0.9355926436048008\n",
            "Best Solution: [0.004915491436617374, 1]\n",
            "ML Metrics: {0: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.3931453671403046, 'accuracy': 0.40476190476190477, 'recall': 0.36750230069305684}, 'custo': {'mtp': 4015234, 'tpi': 0.03408905863761902, 'ms': 15.316902160644531}, 'solution': {'lr': 0.008173306304572338, 'model_index': 0}}, 1: {'model_name': 'ResNet50', 'assertividade': {'precision': 0.3096171802054155, 'accuracy': 0.23015873015873015, 'recall': 0.1788377965703547}, 'custo': {'mtp': 23520326, 'tpi': 0.09884101152420044, 'ms': 89.7229232788086}, 'solution': {'lr': 0.008169279428953099, 'model_index': 2}}, 2: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.23508678539166347, 'accuracy': 0.3373015873015873, 'recall': 0.29257386810470737}, 'custo': {'mtp': 2231558, 'tpi': 0.04945465922355652, 'ms': 8.512718200683594}, 'solution': {'lr': 0.007750224415955002, 'model_index': 1}}, 3: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.3657045830741368, 'accuracy': 0.3412698412698413, 'recall': 0.35750674350336425}, 'custo': {'mtp': 4015234, 'tpi': 0.0594521164894104, 'ms': 15.316902160644531}, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 4: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.2953035336756267, 'accuracy': 0.39285714285714285, 'recall': 0.3297560983148498}, 'custo': {'mtp': 2231558, 'tpi': 0.0539628267288208, 'ms': 8.512718200683594}, 'solution': {'lr': 0.008690641876341252, 'model_index': 1}}, 5: {'model_name': 'ResNet50', 'assertividade': {'precision': 0.3861642065767583, 'accuracy': 0.44841269841269843, 'recall': 0.3872651465428593}, 'custo': {'mtp': 23520326, 'tpi': 0.09154194593429565, 'ms': 89.7229232788086}, 'solution': {'lr': 0.0044454829886935235, 'model_index': 2}}, 6: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.3899265019586549, 'accuracy': 0.4365079365079365, 'recall': 0.3862370646489373}, 'custo': {'mtp': 4015234, 'tpi': 0.05218648910522461, 'ms': 15.316902160644531}, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 7: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.16479010286349735, 'accuracy': 0.32142857142857145, 'recall': 0.2596899224806202}, 'custo': {'mtp': 2231558, 'tpi': 0.049702465534210205, 'ms': 8.512718200683594}, 'solution': {'lr': 0.008842528185337765, 'model_index': 1}}, 8: {'model_name': 'InceptionV3', 'assertividade': {'precision': 0.04453142727479011, 'accuracy': 0.17857142857142858, 'recall': 0.16164505466564963}, 'custo': {'mtp': 24360172, 'tpi': 0.12567037343978882, 'ms': 92.92668151855469}, 'solution': {'lr': 0.009687260779252884, 'model_index': 3}}, 9: {'model_name': 'EfficientNetB0', 'assertividade': {'precision': 0.24894179894179894, 'accuracy': 0.1349206349206349, 'recall': 0.19528593771249833}, 'custo': {'mtp': 4015234, 'tpi': 0.07633677124977112, 'ms': 15.316902160644531}, 'solution': {'lr': 0.01, 'model_index': 0}}, 10: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.5323183760683761, 'accuracy': 0.4642857142857143, 'recall': 0.3785463799293558}, 'custo': {'mtp': 2231558, 'tpi': 0.04039457440376282, 'ms': 8.512718200683594}, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 11: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.44737176869197487, 'accuracy': 0.4603174603174603, 'recall': 0.4274335742072956}, 'custo': {'mtp': 2231558, 'tpi': 0.05407071113586426, 'ms': 8.512718200683594}, 'solution': {'lr': 0.004468780719721807, 'model_index': 1}}, 12: {'model_name': 'MobileNetV2', 'assertividade': {'precision': 0.4513536987121893, 'accuracy': 0.4880952380952381, 'recall': 0.4333709413328646}, 'custo': {'mtp': 2231558, 'tpi': 0.056870877742767334, 'ms': 8.512718200683594}, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 13: {'model_name': 'InceptionV3', 'assertividade': {'precision': 0.11150793650793651, 'accuracy': 0.32142857142857145, 'recall': 0.24088250930356195}, 'custo': {'mtp': 24360172, 'tpi': 0.6650974750518799, 'ms': 92.92668151855469}, 'solution': {'lr': 0.005174912960528561, 'model_index': 3}}, 14: {'model_name': 'InceptionV3', 'assertividade': {'precision': 0.32210129772629775, 'accuracy': 0.24603174603174602, 'recall': 0.27521919745590656}, 'custo': {'mtp': 24360172, 'tpi': 0.6177894771099091, 'ms': 92.92668151855469}, 'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}\n",
            "OACE Metrics: {0: {'model_name': 'EfficientNetB0', 'A': 0.0, 'C': 0.746754924222813, 'Score': 0.5600661931671097, 'solution': {'lr': 0.008173306304572338, 'model_index': 0}}, 1: {'model_name': 'ResNet50', 'A': 0.0, 'C': 0.031222735351751237, 'Score': 0.023417051513813427, 'solution': {'lr': 0.008169279428953099, 'model_index': 2}}, 2: {'model_name': 'MobileNetV2', 'A': 0.16419434692639776, 'C': 0.8119999999999999, 'Score': 0.6500485867315994, 'solution': {'lr': 0.007750224415955002, 'model_index': 1}}, 3: {'model_name': 'EfficientNetB0', 'A': 0.8004349448738249, 'C': 0.746754924222813, 'Score': 0.760174929385566, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 4: {'model_name': 'MobileNetV2', 'A': 0.5184705903013165, 'C': 0.8119999999999999, 'Score': 0.7386176475753291, 'solution': {'lr': 0.008690641876341252, 'model_index': 1}}, 5: {'model_name': 'ResNet50', 'A': 1.0231979099304807, 'C': 0.031222735351751237, 'Score': 0.27921652899643357, 'solution': {'lr': 0.0044454829886935235, 'model_index': 2}}, 6: {'model_name': 'EfficientNetB0', 'A': 1.0273384557591472, 'C': 0.746754924222813, 'Score': 0.8169008071068965, 'solution': {'lr': 0.008491695916522522, 'model_index': 0}}, 7: {'model_name': 'MobileNetV2', 'A': -0.19212758639777694, 'C': 0.8119999999999999, 'Score': 0.5609681034005558, 'solution': {'lr': 0.008842528185337765, 'model_index': 1}}, 8: {'model_name': 'InceptionV3', 'A': -0.9442201606691986, 'C': 0.0004135063209624752, 'Score': -0.23574491042657778, 'solution': {'lr': 0.009687260779252884, 'model_index': 3}}, 9: {'model_name': 'EfficientNetB0', 'A': -0.03140611376185065, 'C': 0.746754924222813, 'Score': 0.552214664726647, 'solution': {'lr': 0.01, 'model_index': 0}}, 10: {'model_name': 'MobileNetV2', 'A': 1.3063705744192033, 'C': 0.8119999999999999, 'Score': 0.9355926436048008, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 11: {'model_name': 'MobileNetV2', 'A': 1.1434057982638959, 'C': 0.8119999999999999, 'Score': 0.894851449565974, 'solution': {'lr': 0.004468780719721807, 'model_index': 1}}, 12: {'model_name': 'MobileNetV2', 'A': 1.0, 'C': 0.8119999999999999, 'Score': 0.859, 'solution': {'lr': 0.004915491436617374, 'model_index': 1}}, 13: {'model_name': 'InceptionV3', 'A': 0.2852818560978563, 'C': 0.0004135063209624752, 'Score': 0.07163059376518592, 'solution': {'lr': 0.005174912960528561, 'model_index': 3}}, 14: {'model_name': 'InceptionV3', 'A': 0.6922535607954682, 'C': 0.0004135063209624752, 'Score': 0.1733735199395889, 'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}\n",
            "M√©todo Finalizado: \n"
          ]
        }
      ],
      "source": [
        "print(f\"Best Model: {best_model}\")\n",
        "print(f\"Best Score: {best_score}\")\n",
        "print(f\"Best Solution: {best_solution}\")\n",
        "print(f\"ML Metrics: {metrics}\")\n",
        "print(f\"OACE Metrics: {oace_metrics}\")\n",
        "print(f\"M√©todo Finalizado: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FeaJBg11F_t",
        "outputId": "fbb585b9-0e77-4b43-e974-b6914b28379f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.3931453671403046,\n",
              "   'accuracy': 0.40476190476190477,\n",
              "   'recall': 0.36750230069305684},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.03408905863761902,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.008173306304572338, 'model_index': 0}},\n",
              " 1: {'model_name': 'ResNet50',\n",
              "  'assertividade': {'precision': 0.3096171802054155,\n",
              "   'accuracy': 0.23015873015873015,\n",
              "   'recall': 0.1788377965703547},\n",
              "  'custo': {'mtp': 23520326,\n",
              "   'tpi': 0.09884101152420044,\n",
              "   'ms': 89.7229232788086},\n",
              "  'solution': {'lr': 0.008169279428953099, 'model_index': 2}},\n",
              " 2: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.23508678539166347,\n",
              "   'accuracy': 0.3373015873015873,\n",
              "   'recall': 0.29257386810470737},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.04945465922355652,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.007750224415955002, 'model_index': 1}},\n",
              " 3: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.3657045830741368,\n",
              "   'accuracy': 0.3412698412698413,\n",
              "   'recall': 0.35750674350336425},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.0594521164894104,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 4: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.2953035336756267,\n",
              "   'accuracy': 0.39285714285714285,\n",
              "   'recall': 0.3297560983148498},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.0539628267288208,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.008690641876341252, 'model_index': 1}},\n",
              " 5: {'model_name': 'ResNet50',\n",
              "  'assertividade': {'precision': 0.3861642065767583,\n",
              "   'accuracy': 0.44841269841269843,\n",
              "   'recall': 0.3872651465428593},\n",
              "  'custo': {'mtp': 23520326,\n",
              "   'tpi': 0.09154194593429565,\n",
              "   'ms': 89.7229232788086},\n",
              "  'solution': {'lr': 0.0044454829886935235, 'model_index': 2}},\n",
              " 6: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.3899265019586549,\n",
              "   'accuracy': 0.4365079365079365,\n",
              "   'recall': 0.3862370646489373},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.05218648910522461,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 7: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.16479010286349735,\n",
              "   'accuracy': 0.32142857142857145,\n",
              "   'recall': 0.2596899224806202},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.049702465534210205,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.008842528185337765, 'model_index': 1}},\n",
              " 8: {'model_name': 'InceptionV3',\n",
              "  'assertividade': {'precision': 0.04453142727479011,\n",
              "   'accuracy': 0.17857142857142858,\n",
              "   'recall': 0.16164505466564963},\n",
              "  'custo': {'mtp': 24360172,\n",
              "   'tpi': 0.12567037343978882,\n",
              "   'ms': 92.92668151855469},\n",
              "  'solution': {'lr': 0.009687260779252884, 'model_index': 3}},\n",
              " 9: {'model_name': 'EfficientNetB0',\n",
              "  'assertividade': {'precision': 0.24894179894179894,\n",
              "   'accuracy': 0.1349206349206349,\n",
              "   'recall': 0.19528593771249833},\n",
              "  'custo': {'mtp': 4015234,\n",
              "   'tpi': 0.07633677124977112,\n",
              "   'ms': 15.316902160644531},\n",
              "  'solution': {'lr': 0.01, 'model_index': 0}},\n",
              " 10: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.5323183760683761,\n",
              "   'accuracy': 0.4642857142857143,\n",
              "   'recall': 0.3785463799293558},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.04039457440376282,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 11: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.44737176869197487,\n",
              "   'accuracy': 0.4603174603174603,\n",
              "   'recall': 0.4274335742072956},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.05407071113586426,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.004468780719721807, 'model_index': 1}},\n",
              " 12: {'model_name': 'MobileNetV2',\n",
              "  'assertividade': {'precision': 0.4513536987121893,\n",
              "   'accuracy': 0.4880952380952381,\n",
              "   'recall': 0.4333709413328646},\n",
              "  'custo': {'mtp': 2231558,\n",
              "   'tpi': 0.056870877742767334,\n",
              "   'ms': 8.512718200683594},\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 13: {'model_name': 'InceptionV3',\n",
              "  'assertividade': {'precision': 0.11150793650793651,\n",
              "   'accuracy': 0.32142857142857145,\n",
              "   'recall': 0.24088250930356195},\n",
              "  'custo': {'mtp': 24360172,\n",
              "   'tpi': 0.6650974750518799,\n",
              "   'ms': 92.92668151855469},\n",
              "  'solution': {'lr': 0.005174912960528561, 'model_index': 3}},\n",
              " 14: {'model_name': 'InceptionV3',\n",
              "  'assertividade': {'precision': 0.32210129772629775,\n",
              "   'accuracy': 0.24603174603174602,\n",
              "   'recall': 0.27521919745590656},\n",
              "  'custo': {'mtp': 24360172,\n",
              "   'tpi': 0.6177894771099091,\n",
              "   'ms': 92.92668151855469},\n",
              "  'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir5FqvYqiZe5",
        "outputId": "36f216fd-cf78-4ece-8a2a-39d21d123fdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: {'model_name': 'EfficientNetB0',\n",
              "  'A': 0.0,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.5600661931671097,\n",
              "  'solution': {'lr': 0.008173306304572338, 'model_index': 0}},\n",
              " 1: {'model_name': 'ResNet50',\n",
              "  'A': 0.0,\n",
              "  'C': 0.031222735351751237,\n",
              "  'Score': 0.023417051513813427,\n",
              "  'solution': {'lr': 0.008169279428953099, 'model_index': 2}},\n",
              " 2: {'model_name': 'MobileNetV2',\n",
              "  'A': 0.16419434692639776,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.6500485867315994,\n",
              "  'solution': {'lr': 0.007750224415955002, 'model_index': 1}},\n",
              " 3: {'model_name': 'EfficientNetB0',\n",
              "  'A': 0.8004349448738249,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.760174929385566,\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 4: {'model_name': 'MobileNetV2',\n",
              "  'A': 0.5184705903013165,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.7386176475753291,\n",
              "  'solution': {'lr': 0.008690641876341252, 'model_index': 1}},\n",
              " 5: {'model_name': 'ResNet50',\n",
              "  'A': 1.0231979099304807,\n",
              "  'C': 0.031222735351751237,\n",
              "  'Score': 0.27921652899643357,\n",
              "  'solution': {'lr': 0.0044454829886935235, 'model_index': 2}},\n",
              " 6: {'model_name': 'EfficientNetB0',\n",
              "  'A': 1.0273384557591472,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.8169008071068965,\n",
              "  'solution': {'lr': 0.008491695916522522, 'model_index': 0}},\n",
              " 7: {'model_name': 'MobileNetV2',\n",
              "  'A': -0.19212758639777694,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.5609681034005558,\n",
              "  'solution': {'lr': 0.008842528185337765, 'model_index': 1}},\n",
              " 8: {'model_name': 'InceptionV3',\n",
              "  'A': -0.9442201606691986,\n",
              "  'C': 0.0004135063209624752,\n",
              "  'Score': -0.23574491042657778,\n",
              "  'solution': {'lr': 0.009687260779252884, 'model_index': 3}},\n",
              " 9: {'model_name': 'EfficientNetB0',\n",
              "  'A': -0.03140611376185065,\n",
              "  'C': 0.746754924222813,\n",
              "  'Score': 0.552214664726647,\n",
              "  'solution': {'lr': 0.01, 'model_index': 0}},\n",
              " 10: {'model_name': 'MobileNetV2',\n",
              "  'A': 1.3063705744192033,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.9355926436048008,\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 11: {'model_name': 'MobileNetV2',\n",
              "  'A': 1.1434057982638959,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.894851449565974,\n",
              "  'solution': {'lr': 0.004468780719721807, 'model_index': 1}},\n",
              " 12: {'model_name': 'MobileNetV2',\n",
              "  'A': 1.0,\n",
              "  'C': 0.8119999999999999,\n",
              "  'Score': 0.859,\n",
              "  'solution': {'lr': 0.004915491436617374, 'model_index': 1}},\n",
              " 13: {'model_name': 'InceptionV3',\n",
              "  'A': 0.2852818560978563,\n",
              "  'C': 0.0004135063209624752,\n",
              "  'Score': 0.07163059376518592,\n",
              "  'solution': {'lr': 0.005174912960528561, 'model_index': 3}},\n",
              " 14: {'model_name': 'InceptionV3',\n",
              "  'A': 0.6922535607954682,\n",
              "  'C': 0.0004135063209624752,\n",
              "  'Score': 0.1733735199395889,\n",
              "  'solution': {'lr': 0.004751354803375619, 'model_index': 3}}}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oace_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enq1ouE-yILX"
      },
      "source": [
        "Salvando m√©tricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIdTSuWEyJ0b"
      },
      "outputs": [],
      "source": [
        "# Salvando as m√©tricas\n",
        "with open('ML_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f)\n",
        "with open('OACE_metrics.json', 'w') as f:\n",
        "    json.dump(oace_metrics, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
